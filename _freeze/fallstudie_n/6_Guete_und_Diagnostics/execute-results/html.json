{
  "hash": "6250a3186ee438c59af8f9d5643a1baa",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute:\n  echo: false   # set to true to show musterlösung\n  output: false # set to true to show musterlösung\ncode-fold: true\ncode-summary: \"Musterlösung\"\nknitr:\n  opts_chunk: \n    collapse: true\n---\n\n\n# Modellgüte und -diagnostics MM\n\n## Libraries laden\n\nPackages die wir für die Modelle und die Diagnostics brauchen\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(\"lme4\")\nlibrary(\"bbmle\")\nlibrary(\"MuMIn\")\nlibrary(\"dplyr\")\nlibrary(\"readr\")\nlibrary(\"ggplot2\")\nlibrary(\"DHARMa\")\nlibrary(\"car\")\nlibrary(\"MASS\")\nlibrary(\"ROCR\")\nlibrary(\"sjPlot\")\nlibrary(\"ggeffects\")\nlibrary(\"sjstats\")\nlibrary(\"cowplot\")\nlibrary(\"gstat\")\nlibrary(\"purrr\")\nlibrary(\"broom.mixed\")\n```\n:::\n\n\n## Ausgangslage\n\n- Der Modellfit aus Aufgabe 5 von letzter Woche dient als Ausgangspunkt für die heutigen Übungen. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nDF_mod_day <- read_delim(\"datasets/fallstudie_n/Aufgabe4_Datensatz_Habitatnutzung_Modelle_241028.csv\", delim = \";\") |>\n  filter(time_of_day == \"day\") |>\n  mutate(\n    slope_scaled = scale(slope),\n    topo_pos_scaled = scale(topo_pos),\n    us_scaled = scale(us_2014),\n    os_scaled = scale(os_2014),\n    forest_prop_scaled = scale(forest_prop),\n    dist_road_trails_scaled = scale(dist_road_trails),\n    dist_road_only_scaled = scale(dist_road_only),\n    dist_sett_scaled = scale(dist_sett),\n    id = as.factor(id)\n  )\n\nf <- pres_abs ~\n  slope_scaled +\n  topo_pos_scaled +\n  us_scaled +\n  forest_prop_scaled +\n  dist_road_only_scaled +\n  dist_sett_scaled \n\nf <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") |> as.formula()\n\nm_day <- glmer(f, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\nall_m <- dredge(m_day)\n\navgmodel <- model.avg(all_m, rank = \"AICc\", subset = delta < 2)\nsummary(avgmodel)\n```\n:::\n\n\n- Die Modellresultate aus dem avgmodel sind grundsätzlich die finalen Resultate die bereits interpretiert werden könnten. Allerdings funktionieren die Diagnosetests und die Darstellung der Resultate mit diesem gemittelten Modell nicht sehr gut, weshalb wir einen re-fit mit glmer machen müssen (an den Resultaten ändert sich dadurch nichts) \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# hier zum Vergleich, dass die Resulate sich nur marginal verändern\n\nsummary(avgmodel)\nsummary(m_day)\n```\n:::\n\n\n## Aufgabe 1\n\nBerechung der AUC (area under the receiver operating characteristic curve) **= Mass der Modellgüte**\n\nFür die Berechnung des AUC findet ihr weiterführende Informationen unter: [Link](simtest.pdf) \n\n\n::: {.cell}\n\n```{.r .cell-code}\nprob <- predict(m_day, type = c(\"response\"))\npred <- prediction(prob, DF_mod_day$pres_abs)\n\n# AUC\n\nauc <- performance(pred, measure = \"auc\")@y.values[[1]]\nauc\n```\n:::\n\n\n## Aufgabe 2\n\nInterpretieren der Modell-Residuen mittels Tests auf verschiedene Aspekte\n\n- Model testing for over/underdispersion, zeroinflation and spatial autocorrelation following the DHARMa package.\n- unbedingt die Vignette des DHARMa-Package konsultieren: [Link](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Residuals werden über eine Simulation auf eine Standard-Skala transformiert und\n# können anschliessend getestet werden. Dabei kann die Anzahl Simulationen eingestellt\n# werden (dauert je nach dem sehr lange)\n\nsimulationOutput <- simulateResiduals(fittedModel = m_day, n = 10000)\n\n# plotting and testing scaled residuals\n\nplot(simulationOutput)\ntestResiduals(simulationOutput)\n\n# The most common concern for GLMMs is overdispersion, underdispersion and\n# zero-inflation.\n\n# separate test for dispersion\n\ntestDispersion(simulationOutput)\n\n# test for Zeroinflation\n\ntestZeroInflation(simulationOutput)\n\n# test for spatial Autocorrelation\n\n# calculating x, y positions per group\ngroupLocations <- aggregate(DF_mod_day[, 3:4], list(DF_mod_day$x, DF_mod_day$y), mean)\ngroupLocations$group <- paste(groupLocations$Group.1, groupLocations$Group.2)\ngroupLocations <- groupLocations |> dplyr::select(x,y,group)\n\n\n\n# calculating residuals per group\nres2 = recalculateResiduals(simulationOutput, group = groupLocations$group)\n\n# running the spatial test on grouped residuals\ntestSpatialAutocorrelation(res2, groupLocations$x, groupLocations$y, plot = F)\n\n# Testen auf Multicollinearität (dh zu starke Korrelationen im finalen Modell, zB falls\n# auf Grund der ökologischen Plausibilität stark korrelierte Variablen im Modell)\n# use VIF values: if values less then 5 is ok (sometimes > 10), if mean of VIF values\n# not substantially greater than 1 (say 5), no need to worry.\n\ncar::vif(m_day)\nmean(car::vif(m_day))\n```\n:::\n\n\n## Aufgabe 3\n\nGraphische Darstellung der Modellresultate\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# graphische Darstellung der gesamten Modellresultate\n\nplot_model(m_day, transform = NULL, show.values = TRUE, value.offset = .3)\n\n# Plotten der vorhergesagten Wahrscheinlichkeit, dass ein Kreis besetzt ist, in\n# Abhängigkeit der erklärenden Variable basierend auf den Modellresultaten.\n\nplot_model(m_day, type = \"pred\", terms = \"us_scaled [all]\")\n\n# Problem: skalierte Variablen lassen sich nicht so ohne weiteres plotten, hier ein Hack um das Problem zu umgehen (Danke chatGPT!). \n# Die Einstellungen müssen für jede Variable separat geändert werden\n\n# Plot erstellen\nplot_obj <- plot_model(m_day, type = \"pred\", terms = \"us_scaled [all]\")\n\n# Rücktransformation für die Achse: hier skalierten Werte anpassen\n\noriginal_mean <- mean(DF_mod_day$us_2014)  \noriginal_sd <- sd(DF_mod_day$us_2014)  \n\nmin_us <- min(DF_mod_day$us_2014)\nmax_us <- max(DF_mod_day$us_2014)\n\n\nplot_obj +\n  scale_x_continuous(\n    limits = c((min_us - original_mean) / original_sd, (max_us - original_mean) / original_sd),  # skaliert\n    breaks = seq((min_us - original_mean) / original_sd, (max_us - original_mean) / original_sd, length.out = 5),  # automatische Schritte\n    labels = function(x) round(x * original_sd + original_mean, 2),  # Rücktransformierte Labels\n    name = \"Deckungsgrad Strauchschicht\"\n  )\n\n\n# Funktion um viele Plots auf einem zusammenbringen: cowplot-package (hat auch sonst\n# gute Funktionen für schöne Layouts für Grafiken)\n\ncowplot::plot_grid()\n```\n:::\n\n\n## Aufgabe 4\n\nErmittlung des individuellen Beitrags der einzelnen Variablen im Gesamtmodell (leave-one-out Ansatz)\n\n- Bestimmen delta AIC nach @coppes2017 → Vergleich des Gesamtmodells gegenüber einem Modell ohne die entsprechende Variable.\n- Auftrag auf nächste Woche: Kurze Vorstellung der Modellresultate & Diagnostics im Plenum und Diskussion der Ergebnisse (keine PP-Präsentation nötig)\n\n\n::: {.cell}\n\n:::\n\n\n## \n\n\n::: {.cell}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}