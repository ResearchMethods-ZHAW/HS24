{
  "hash": "eb0fcff8e8fc869d39011c3b7d88c55b",
  "result": {
    "markdown": "---\nexecute:\n  echo: true  # set to true to show musterlösung\n  output: true # set to true to show musterlösung\ncode-fold: true\ncode-summary: \"Musterlösung\"\nknitr:\n  opts_chunk: \n    collapse: true\n---\n\n\n# BiEc5_N Variablenselektion MM\n\n## Libraries laden\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(\"sf\")\nlibrary(\"terra\")\nlibrary(\"dplyr\")\nlibrary(\"readr\")\nlibrary(\"ggplot2\")\nlibrary(\"PerformanceAnalytics\")\nlibrary(\"pastecs\")\nlibrary(\"lme4\")\nlibrary(\"bbmle\")\nlibrary(\"MuMIn\")\nlibrary(\"MASS\")\n```\n:::\n\n\n## Variablenselektion\n\n→ Vorgehen analog @coppes2017\n\n## Aufgabe 1\n\nMit dem folgenden Code kann eine simple Korrelationsmatrix aufgebaut werden, vergl. Aufgabe 5 vorangehende Woche \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nDF_mod <- read_delim(\"datasets/fallstudie_n/Aufgabe4_Datensatz_Habitatnutzung_Modelle_231027_moodle.csv\", delim = \";\")\n\nDF_mod_day <- DF_mod |>\n  filter(time_of_day == \"day\")\n\nround(cor(DF_mod_day[, 6:14], method = \"kendall\"), 2)\n##                slope topo_pos dist_road_all dist_road_only dist_sett remoteness\n## slope           1.00     0.07          0.14           0.17      0.10       0.59\n## topo_pos        0.07     1.00          0.05           0.08      0.04       0.00\n## dist_road_all   0.14     0.05          1.00           0.85     -0.05       0.35\n## dist_road_only  0.17     0.08          0.85           1.00     -0.06       0.34\n## dist_sett       0.10     0.04         -0.05          -0.06      1.00       0.06\n## remoteness      0.59     0.00          0.35           0.34      0.06       1.00\n## forest_prop     0.17     0.00         -0.09          -0.09      0.40       0.12\n## us_2014         0.22    -0.04         -0.06          -0.03      0.09       0.13\n## os_2014         0.34     0.04         -0.06          -0.04      0.23       0.24\n##                forest_prop us_2014 os_2014\n## slope                 0.17    0.22    0.34\n## topo_pos              0.00   -0.04    0.04\n## dist_road_all        -0.09   -0.06   -0.06\n## dist_road_only       -0.09   -0.03   -0.04\n## dist_sett             0.40    0.09    0.23\n## remoteness            0.12    0.13    0.24\n## forest_prop           1.00    0.31    0.52\n## us_2014               0.31    1.00    0.42\n## os_2014               0.52    0.42    1.00\n\n# hier kann die Schwelle für die Korrelation gesetzt werden, 0.7 ist liberal /\n# 0.5 konservativ\n\ncor <- round(cor(DF_mod_day[, 6:14], method = \"kendall\"), 2)\ncor[abs(cor) < 0.7] <- 0\ncor\n##                slope topo_pos dist_road_all dist_road_only dist_sett remoteness\n## slope              1        0          0.00           0.00         0          0\n## topo_pos           0        1          0.00           0.00         0          0\n## dist_road_all      0        0          1.00           0.85         0          0\n## dist_road_only     0        0          0.85           1.00         0          0\n## dist_sett          0        0          0.00           0.00         1          0\n## remoteness         0        0          0.00           0.00         0          1\n## forest_prop        0        0          0.00           0.00         0          0\n## us_2014            0        0          0.00           0.00         0          0\n## os_2014            0        0          0.00           0.00         0          0\n##                forest_prop us_2014 os_2014\n## slope                    0       0       0\n## topo_pos                 0       0       0\n## dist_road_all            0       0       0\n## dist_road_only           0       0       0\n## dist_sett                0       0       0\n## remoteness               0       0       0\n## forest_prop              1       0       0\n## us_2014                  0       1       0\n## os_2014                  0       0       1\n```\n:::\n\n\n## Aufgabe 2\n\nSkalieren der Variablen, damit ihr Einfluss vergleichbar wird (Befehl scale(); Problem verschiedene Skalen der Variablen (bspw. Neigung in Grad, Distanz in Metern));\nUmwandeln der Reh-ID in einen Faktor, damit dieser als Random Factor ins Model eingespiesen werden kann.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nDF_mod_day <- DF_mod_day |>\n  mutate(\n    slope_scaled = scale(slope),\n    topo_pos_scaled = scale(topo_pos),\n    us_scaled = scale(us_2014),\n    os_scaled = scale(os_2014),\n    forest_prop_scaled = scale(forest_prop),\n    dist_road_all_scaled = scale(dist_road_all),\n    dist_road_only_scaled = scale(dist_road_only),\n    dist_sett_scaled = scale(dist_sett),\n    remoteness_scaled = scale(remoteness),\n    id = as.factor(id)\n  )\n```\n:::\n\n\n## Aufgabe 3\n\n**Selektion der Variablen in einem univariaten Model**\n\nEin erstes GLMM (Generalized Linear Mixed Effects Modell) aufbauen: Funktion und Modelformel\n\n> wichtige [Seite](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) auf der man viele Hilfestellungen zu GLMM’s finden kann.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# wir werden das package lme4 mit der Funktion glmer verwenden\n\n# die Hilfe von glmer aufrufen: ?glmer\n\n# glmer(formula, data = , family = binomial)\n\n# 1) formula:\n# Abhängige Variable ~ Erklärende Variable + Random Factor\n# In unseren Modellen kontrollieren wir für individuelle Unterschiede bei den Rehen\n# indem wir einen Random Factor definieren => (1 | id)\n\n# 2) data:\n# euer Datensatz\n\n# 3) family:\n# hier binomial\n\n# warum binomial? Verteilung Daten der Abhängigen Variable Präsenz/Absenz\n\nggplot(DF_mod_day, aes(pres_abs)) +\n  geom_histogram()\n```\n\n::: {.cell-output-display}\n![](5_Variablenselektion_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\n\n# --> Binäre Verteilung => Binomiale Verteilung mit n = 1\n\n# und wie schaut die Verteilung der Daten der Abhängigen Variable Nutzungsintensität\n# (nmb, werden wir in diesem Kurs aber nicht genauer anschauen) aus?\n```\n:::\n\n\n## Aufgabe 4\n\nMit der GLMM Formel bauen wir in einem ersten Schritt eine univariate Variablenselektion auf.\n\n***Als abhängige Variable verwenden wir die Präsenz/Absenz der Rehe in den Kreisen***\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Die erklärende Variable in m1 ist die erste Variable der korrelierenden Variablen\n# Die erklärende Variable in m2 ist die zweite Variable der korrelierenden Variablen\n\nm1 <- glmer(Abhaengige_Variable ~ Erklaerende_Variable + (1 | id),\n  data = DF_mod_day,\n  family = binomial\n)\n\nm2 <- glmer(Abhaengige_Variable ~ Erklaerende_Variable + (1 | id),\n  data = DF_mod_day,\n  family = binomial\n)\n\n# mit dieser Funktion können die Modellergebnisse inspiziert werden\nsummary(m1)\n\n# Mit dieser Funktion kann der Informationgehalt der beiden Modelle gegeneinander\n# abgeschätzt werden\nbbmle::AICtab(m1, m2)\n\n# tieferer AIC -> besser (AIC = Akaike information criterion)\n\n# ==> dieses Vorgehen muss nun für alle korrelierten Variablen für jeden Teildatensatz\n# (Tag/Nacht) durchgeführt werden, um nur noch nicht (R < 0.7) korrelierte Variablen\n# in das Modell einfliessen zu lassen\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- glmer(pres_abs ~ dist_road_all_scaled + (1 | id), data = DF_mod_day, family = binomial)\nm2 <- glmer(pres_abs ~ dist_road_only_scaled + (1 | id), data = DF_mod_day, family = binomial)\n\nsummary(m1)\n## Generalized linear mixed model fit by maximum likelihood (Laplace\n##   Approximation) [glmerMod]\n##  Family: binomial  ( logit )\n## Formula: pres_abs ~ dist_road_all_scaled + (1 | id)\n##    Data: DF_mod_day\n## \n##      AIC      BIC   logLik deviance df.resid \n##   5104.9   5123.7  -2549.4   5098.9     3961 \n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.1046 -0.7564 -0.6277  1.0812  1.9219 \n## \n## Random effects:\n##  Groups Name        Variance Std.Dev.\n##  id     (Intercept) 0.1996   0.4467  \n## Number of obs: 3964, groups:  id, 12\n## \n## Fixed effects:\n##                      Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)          -0.31120    0.13418  -2.319   0.0204 *  \n## dist_road_all_scaled  0.37745    0.03848   9.808   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## dst_rd_ll_s -0.004\n\nbbmle::AICtab(m1, m2)\n##    dAIC df\n## m2 0.0  3 \n## m1 6.5  3\n\n# tieferer AIC -> besser (AIC = Akaike information criterion) -> als deltaAIC\n# ausgewiesen besser == Distanz zu Strassen\n\n# ==> dieses Vorgehen muss nun für alle korrelierten Variablen für jeden\n# Teildatensatz (geringe Störung/starke Störung) durchgeführt werden, um nur\n# noch nicht (R < 0.7) korrelierte Variablen in das Modell einfliessen zu\n# lassen\n```\n:::\n\n\n## Aufgabe 5\n\n**Selektion der Variablen in einem multivariaten Model**\n\nMit folgendem Code kann eine automatisierte Variablenselektion (dredge-Funktion) und ein Modelaveraging aufgebaut werden (siehe auch Stats-Skript von J.Dengler & Team)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# hier wird die Formel für die dredge-Funktion vorbereitet (die Variablen V1-V8\n# sind jene welche nach der univariaten Variablenselektion noch übrig bleiben)\n\nf <- pres_abs ~\n  V1 +\n  V2 +\n  V3 +\n  V4 +\n  V5 +\n  V6 +\n  V7 +\n  V8\n\n# in diesem Befehl kommt der Random-Factor (das Reh) hinzu und es wird eine Formel\n# daraus gemacht\n\nf_dredge <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") |> as.formula()\n\n# Das Modell mit dieser Formel ausführen\n\nm <- glmer(f_dredge, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\n# Das Modell in die dredge-Funktion einfügen (siehe auch unbedingt ?dredge)\n\nall_m <- dredge(m)\n\n# Importance values der einzelnen Variablen (Gibt an, wie bedeutsam eine bestimmte\n# Variable ist, wenn man viele verschiedene Modelle vergleicht (multimodel inference))\n\nsw(all_m)\n\n# Schlussendlich wird ein Modelaverage durchgeführt (Schwellenwert für das delta-AIC = 2)\n\navgmodel <- model.avg(all_m, rank = \"AICc\", subset = delta < 2)\nsummary(avgmodel)\n\n# ==> für den Nachtdatensatz muss der gleiche Prozess der Variablenselektion\n# durchgespielt werden.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# hier wird die Formel für die dredge-Funktion vorbereitet (die Variablen V1-V8\n# sind jene welche nach der univariaten Variablenselektion noch übrig bleiben)\n\nf <- pres_abs ~\n  slope_scaled +\n  topo_pos_scaled +\n  us_scaled +\n  os_scaled +\n  forest_prop_scaled +\n  dist_road_only_scaled +\n  dist_sett_scaled +\n  remoteness_scaled\n\n# inn diesem Befehl kommt der Random-Factor (das Reh) hinzu und es wird eine Formel\n# daraus gemacht\n\nf_dredge <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") |> as.formula()\n\n# Das Modell mit dieser Formel ausführen\n\nm <- glmer(f_dredge, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\n# Das Modell in die dredge-Funktion einfügen (siehe auch unbedingt ?dredge)\n\nall_m <- dredge(m)\n\n# Importance values der einzelnen Variablen (Gibt an, wie bedeutsam eine bestimmte\n# Variable ist, wenn man viele verschiedene Modelle vergleicht (multimodel inference))\n\nsw(all_m)\n##                      dist_road_only_scaled forest_prop_scaled us_scaled\n## Sum of weights:      1.00                  1.00               1.00     \n## N containing models:  128                   128                128     \n##                      remoteness_scaled dist_sett_scaled slope_scaled os_scaled\n## Sum of weights:      1.00              0.42             0.32         0.29     \n## N containing models:  128               128              128          128     \n##                      topo_pos_scaled\n## Sum of weights:      0.27           \n## N containing models:  128\n\n# Schlussendlich wird ein Modelaverage durchgeführt (Schwellenwert für das delta-AIC = 2)\n\navgmodel <- model.avg(all_m, rank = \"AICc\", subset = delta < 2)\nsummary(avgmodel)\n## \n## Call:\n## model.avg(object = get.models(object = all_m, subset = delta < \n##     2), rank = \"AICc\")\n## \n## Component model call: \n## glmer(formula = pres_abs ~ <4 unique rhs>, data = DF_mod_day, family = \n##      binomial, na.action = na.fail)\n## \n## Component models: \n##       df   logLik    AICc delta weight\n## 1357   6 -2261.70 4535.41  0.00   0.39\n## 12357  7 -2261.02 4536.07  0.65   0.28\n## 13567  7 -2261.52 4537.06  1.65   0.17\n## 13457  7 -2261.60 4537.23  1.82   0.16\n## \n## Term codes: \n## dist_road_only_scaled      dist_sett_scaled    forest_prop_scaled \n##                     1                     2                     3 \n##             os_scaled     remoteness_scaled          slope_scaled \n##                     4                     5                     6 \n##             us_scaled \n##                     7 \n## \n## Model-averaged coefficients:  \n## (full average) \n##                        Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n## (Intercept)           -0.437730   0.148042    0.148087   2.956  0.00312 ** \n## dist_road_only_scaled  0.510519   0.052598    0.052614   9.703  < 2e-16 ***\n## forest_prop_scaled     0.844263   0.058809    0.058826  14.352  < 2e-16 ***\n## remoteness_scaled     -0.255199   0.056758    0.056775   4.495    7e-06 ***\n## us_scaled              0.382072   0.040946    0.040959   9.328  < 2e-16 ***\n## dist_sett_scaled      -0.020550   0.046737    0.046744   0.440  0.66021    \n## slope_scaled          -0.006037   0.027844    0.027851   0.217  0.82839    \n## os_scaled              0.004232   0.026310    0.026317   0.161  0.87225    \n##  \n## (conditional average) \n##                       Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n## (Intercept)           -0.43773    0.14804     0.14809   2.956  0.00312 ** \n## dist_road_only_scaled  0.51052    0.05260     0.05261   9.703  < 2e-16 ***\n## forest_prop_scaled     0.84426    0.05881     0.05883  14.352  < 2e-16 ***\n## remoteness_scaled     -0.25520    0.05676     0.05678   4.495    7e-06 ***\n## us_scaled              0.38207    0.04095     0.04096   9.328  < 2e-16 ***\n## dist_sett_scaled      -0.07295    0.06270     0.06272   1.163  0.24479    \n## slope_scaled          -0.03532    0.05918     0.05919   0.597  0.55069    \n## os_scaled              0.02690    0.06157     0.06159   0.437  0.66226    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n\n#| eval: false\n#| error: true\n#| echo: false\n\n# hier wird die Formel für die dredge-Funktion vorbereitet (die Variablen V1-V8\n# sind jene welche nach der univariaten Variablenselektion noch übrig bleiben)\n\nf <- pres_abs ~\n  slope_scaled +\n  topo_pos_scaled +\n  us_scaled +\n  os_scaled +\n  forest_prop_scaled +\n  dist_road_only_scaled +\n  dist_road_all_scaled +\n  dist_sett_scaled +\n  remoteness_scaled\n\n# inn diesem Befehl kommt der Random-Factor (das Reh) hinzu und es wird eine Formel\n# daraus gemacht\n\nf_dredge <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") |> as.formula()\n\n# Das Modell mit dieser Formel ausführen\n\nm <- glmer(f_dredge, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\ncar::vif(m)\n##          slope_scaled       topo_pos_scaled             us_scaled \n##              2.228320              1.098040              1.239462 \n##             os_scaled    forest_prop_scaled dist_road_only_scaled \n##              2.613227              2.737806              5.816134 \n##  dist_road_all_scaled      dist_sett_scaled     remoteness_scaled \n##              6.032018              1.434214              2.554936\nmean(car::vif(m))\n## [1] 2.861573\n```\n:::",
    "supporting": [
      "5_Variablenselektion_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}