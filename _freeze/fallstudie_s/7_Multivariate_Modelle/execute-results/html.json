{
  "hash": "ad51b67e61ec8fd1728dbb9906237ccb",
  "result": {
    "markdown": "---\ndate: 2023-10-31\nlesson: Multivariate Modelle\nthema: Statistisch schliessend\nindex: 2\nexecute: \n  echo: true   # set to true to show musterlösung\n  output: false\ncode-fold: true\ncode-summary: \"Musterlösung\"\nknitr:\n  opts_chunk: \n    collapse: true\n---\n\n\n# Multivariate Modelle\n\n\n\n\n\n\n\nNachdem die deskriptiven Resultate vorliegen, kann jetzt die Berechnung eines multivariaten Modells angegangen werden. Das Ziel ist es, den Zusammenhang zwischen der gesamten Anzahl Besucher:innen (Total) und verschiedenen erklärenden Variablen (Wochentag, Ferien, Monat, Jahr, Phasen der Covid-Pandemie, Sonnenscheindauer, Höchsttemperatur, Niederschlagssumme) aufzuzeigen, und das während dem Tag, der Dämmerung und der Nacht (siehe dazu auch [Aufgabenstellung Abschlussbericht]).\n\n\n## Aufgabe 1: Verbinden von Daten\n\nAktuell haben wir noch zwei verschiedene Datensätze von Interesse:\n\n1) Einen mit den Besuchszahlen pro Tageszeit von Besucher:innen mit den dazugehörigen Datumsinformationen (Datensatz \"depo_daytime\" - zu Tageszeiten und Wochenende / Werktag aggregierte Stunden) \n\n2) und einen mit den Wetterparametern pro Tag (\"meteo_day\"). \n\n- Diese beiden Datensätze müssen miteinander verbunden werden. __Ziel__: Ein Datensatz mit den __täglichen Zähldaten__ (weiter unterteilt nach Tageszeit) und Conviniencevariablen wie Phase Covid, Ferien Ja oder Nein, Jahr, Monat, KW, Tageszeit, Wochenendtag oder Werktag, angereichert mit __Wetterdaten__.\n\n- Der neue Datensatz soll \" __umwelt__ \" heissen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\numwelt <- inner_join(depo_daytime, meteo_day, by = c(\"Jahr\", \"Monat\", \"KW\", \"Wochenende\"))\n```\n:::\n\n\n- Sind durch das Zusammenführen NA's entstanden? Falls ja, müssen __alle__ für die weiteren Auswertungen ausgeschlossen werden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# es darf keine NA's im datensatz haben\nsum(is.na(umwelt))\n# umwelt <- na.omit(umwelt)\nsummary(umwelt)\n```\n:::\n\n\n\n## Aufgabe 2: Skalieren\n\n### 2a) \n\n- Vergewissert euch, dass die numerischen Messwerte zu Wetter auch in numerischer Form vorliegen. (__is.numeric()__)\n\n- Nachfolgende Schritte funktionieren nur, wenn __umwelt__ als data.frame vorliegt! Prüft das und ändert das, falls noch kein __data.frame__ (Hinweis: auch ein \"tibble\" funktioniert nicht, obwohl bei der Abfrage __is.data.frame()__ TRUE angegeben wird. Damit ihr beim scalen keine NaN Werte erhaltet, wendet ihr darum am besten in allen Fällen zuerst den Befehl __as.data.frame()__ an).\n\n\n::: {.cell}\n\n```{.r .cell-code}\numwelt <- as.data.frame(umwelt)\n```\n:::\n\n\n\n- Unser Modell kann in der abhängigen Variabel nur mit Ganzzahlen (Integer) umgehen. Daher müssen Kommazahlen in Integer umgewandelt werden. Zum Glück haben wir das schon gemacht und uns bleibt nichts weiter zu tun. =)\n\n### 2b) \n\n- Problem: verschiedene Skalen der Variablen (z.B. Temperatur in Grad Celsius, Niederschlag in Millimeter und Sonnenscheindauer in %)\n\n- Lösung: Skalieren aller Variablen mit Masseinheiten gemäss unterstehendem Code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\numwelt <- umwelt |> \n  mutate(tre200jx_scaled = scale(tre200jx)|>\n  ...\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\numwelt <- umwelt |>\n  mutate(\n    tre200jx_scaled = scale(tre200jx),\n    tre200nx_scaled = scale(tre200nx),\n    rre150j0_scaled = scale(rre150j0),\n    rre150n0_scaled = scale(rre150n0),\n    sremaxdv_scaled = scale(sremaxdv)\n  )\n```\n:::\n\n\n\n## Aufgabe 3: Korrelationen und Variablenselektion\n\n### 3a) \n\nKorrelierende Variablen können das Modellergebnis verfälschen. Daher muss vor der Modelldefinition auf Korrelation zwischen den Messwerten getestet werden. Welches sind die erklärenden Variablen, welches ist die Abhängige? (Ihr müsst nicht prüfen, ob die Voraussetzungen zur Berechnung von Korrelationen erfüllt sind)\n\n- Teste mittels folgendem Code auf eine Korrelation zwischen den Messwerten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor <- cor(subset(umwelt, select = c(ERSTE SPALTE MIT ERKLAERENDEN MESSWERTEN : \n                     LETZTE SPALTE MIT ERKLAERENDEN MESSWERTEN)))\n\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor <- cor(subset(umwelt, select = c(tre200nx: sremaxdv)))\n```\n:::\n\n\n### 3b) \n\nMit dem folgenden Code kann eine Korrelationsmatrix (mit den Messwerten) aufgebaut werden. Hier kann auch die Schwelle für die Korrelation gesetzt werden (0.7 ist liberal / 0.5 konservativ).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor[abs(cor) < 0.7] <- 0 # Setzt alle Werte kleiner 0.7 auf 0\n```\n:::\n\n\nZur Visualisierung kann ein Plot erstellt werden.\n\n\n\n::: {.cell outpot='true'}\n\n```{.r .cell-code}\nchart.Correlation(subset(umwelt, select = c(tre200nx: sremaxdv)), \n                  histogram = TRUE, pch = 19)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchart.Correlation(subset(umwelt, select = c(ERSTE SPALTE MIT ERKLAERENDEN MESSWERTEN : \n                     LETZTE SPALTE MIT ERKLAERENDEN MESSWERTEN)), \n                  histogram = TRUE, pch = 19)\n```\n:::\n\n\n\nWo kann eine kritische Korrelation beobachtet werden? Kann man es verantworten, trotzdem alle (Wetter)parameter in das Modell zu geben? \n\nFalls ja: warum? Falls nein: schliesst den betreffenden Parameter aus. Wenn ihr Parameter ausschliesst: welchen der beiden korrelierenden Parameter behaltet ihr im Modell?\n\n\n### 3c)\n\nAktuell haben wir im umwelt-Datensatz noch alle Tageszeiten zusammen gespeichert. Für die Berechnung der Modelle unterteilen wir das noch in Tag, Dämmerung (Morgen- und Abenddämmerung zusammen) und Nacht. Hier eine Inspiration dazu:\n\n\n::: {.cell}\n\n```{.r .cell-code}\numwelt_day <- umwelt |> \n  filter(Tageszeit == \"Tag\")\n\numwelt_duskdawn <- ...\n\numwelt_night <- ...\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\numwelt_day <- umwelt |> \n  filter(Tageszeit == \"Tag\")\n\numwelt_duskdawn <- umwelt |> \n  filter(Tageszeit == \"Morgen\" | Tageszeit == \"Abend\" )\n\numwelt_night <- umwelt |> \n  filter(Tageszeit == \"Nacht\")\n```\n:::\n\n\n\n## Aufgabe 4 (OPTIONAL): Automatische Variablenselektion\n\nFühre die dredge-Funktion und ein Modelaveraging durch. Der Code dazu ist unten. \nWas passiert in der Funktion? Macht es Sinn, die Funktion auszuführen?\n\n__Hinweis:__ untenstehender Code ist sehr rechenentensiv.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hier wird die Formel für die dredge-Funktion vorbereitet\nf <- Total ~ Wochentag + Ferien + Phase + Monat +\n    tre200jx_scaled + rre150j0_scaled + rre150n0_scaled +\n    sremaxdv_scaled\n# Jetzt kommt der Random-Factor hinzu und es wird eine Formel daraus gemacht\nf_dredge <- paste(c(f, \"+ (1|Jahr)\"), collapse = \" \") |>\n    as.formula()\n# Das Modell mit dieser Formel ausführen\nm <- glmer.nb(f_dredge, data = umwelt, na.action = \"na.fail\")\n# Das Modell in die dredge-Funktion einfügen (siehe auch ?dredge)\nall_m <- dredge(m)\n# suche das beste Modell\nprint(all_m)\n# Importance values der Variablen\n# hier wird die wichtigkeit der Variablen in den verschiedenen Modellen abgelesen\nMuMIn::sw(all_m)\n\n# Schliesslich wird ein Modelaverage durchgeführt\n# Schwellenwert für das delta-AIC = 2\navgmodel <- model.avg(all_m, rank = \"AICc\", subset = delta < 2)\nsummary(avgmodel)\n```\n:::\n\n\n\n\n## Aufgabe 5: Verteilung der abhängigen Variabel pruefen\n\nDie Verteilung der abhängigen Variabel bestimmt, was für ein Modell geschrieben werden kann. Alle Modelle gehen von einer bestimmten gegebenen Verteilung aus. Wenn diese Annahme verletzt wird, kann es sein, dass das Modellergebnis nicht valide ist.\n\nUntenstehender Codeblock zeigt, wie unsere Daten auf verschiedene Verteilungen passen.\n\n__Hinweis:__ es kann sein, dass nicht jede Verteilung geplottet werden kann, es erscheint eine Fehlermeldung. Das ist nicht weiter schlimm, die betreffende Verteilung kann gelöscht werden. Analog muss das auch im Befehl __gofstat()__ passieren.\n\n- Die besten drei Verteilungen (gemäss AIC) sollen zur Visualisierung geplottet werden. Dabei gilt, je besser die schwarze Punktlinie (eure Daten) auf die farbigen Linien (theoretische Verteilungen) passen, desto besser ist diese Verteilung geeignet.\n\n__Hinweis:__ CDF =  Cumulative distribution function; Wikipedia = \"Anschaulich entspricht dabei der Wert der Verteilungsfunktion an der Stelle x der Wahrscheinlichkeit, dass die zugehörige Zufallsvariable X einen Wert kleiner oder gleich x annimmt.\" Ihr müsst aber nicht weiter verstehen, wie das berechnet wird, wichtig für euch ist, dass ihr den Plot interpretieren könnt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf1 <- fitdist(umwelt_day$Total, \"norm\") # Normalverteilung\nf1_1 <- fitdist((umwelt_day$Total + 1), \"lnorm\") # log-Normalvert (beachte, dass ich +1 rechne.\n# log muss positiv sein; allerdings kann man die\n# Verteilungen dann nicht mehr miteinander vergleichen).\nf2 <- fitdist(umwelt_day$Total, \"pois\") # Poisson\nf3 <- fitdist(umwelt_day$Total, \"nbinom\") # negativ binomial\nf4 <- fitdist(umwelt_day$Total, \"exp\") # exponentiell\nf5<-fitdist(umwelt_day$Total,\"gamma\")  # gamma (berechnung mit meinen Daten nicht möglich)\nf6 <- fitdist(umwelt_day$Total, \"logis\") # logistisch\nf7 <- fitdist(umwelt_day$Total, \"geom\") # geometrisch\nf8<-fitdist(umwelt_day$Total,\"weibull\")  # Weibull (berechnung mit meinen Daten nicht möglich)\n\ngofstat(list(f1, f2, f3, f4, f6, f7),\n  fitnames = c(\n    \"Normalverteilung\", \"Poisson\",\n    \"negativ binomial\", \"exponentiell\", \"logistisch\",\n    \"geometrisch\"))\n\n# die 2 besten (gemaess Akaike's Information Criterion) als Plot + normalverteilt,\nplot.legend <- c(\"Normalverteilung\", \"exponentiell\", \"negativ binomial\")\n# vergleicht mehrere theoretische Verteilungen mit den empirischen Daten\ncdfcomp(list(f1, f4, f3), legendtext = plot.legend)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](7_Multivariate_Modelle_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n- Wie sind unsere Daten verteilt? Welche Modelle können wir anwenden?\n\n- Wählt die besten Verteilungen pro Tageszeit (umwelt_day, umwelt_duskdawn, umwelt_night) aus und berechnet damit nachfolgend Modelle.\n\n\n## Aufgabe 6: Multivariates Modell berechnen\n\nJetzt gehts ans Eingemachte!\n\nIch verwende hauptsächlich die Funktione __glmmTMB()__. Es ist wahnsinnig schnell und erlaubt viele Spezifikationen:\n[Link](https://glmmtmb.github.io/glmmTMB/articles/glmmTMB.pdf)\n\nAuch __glmer()__ aus der Bibliothek __lme4__ ist recht neu und praktisch (diese Bibliothek wird auch in vielen wissenschaftlichen Papern im Feld Biologie / Wildtiermamagement zitiert).\n[Link](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html)\n\n\n### 6a) Modelle berechnen\n\n__Hinweis:__ Auch wenn wir gerade herausgefunden haben, dass die Verteilung negativ binominal (in meinem Fall) ist, berechne ich für den Vergleich zuerst ein \"einfaches Modell\" der Familie poisson. Alternative Modelle rechnen wir in später. Wir starten mit dem TAG (Datensatz __umwelt_day__).\n\n- Die Totale Besucheranzahl pro Tageszeit soll durch die abhängigen Variablen erklärt werden (Datensatz \"umwelt_day\"). Die einzelnen Jahre sollen hierbei nicht beachtet werden, sie werden als \"random factor\" bestimmt. \n\nFrage: Warum bestimmen wir das Jahr als random factor?\n\nFalls ihr der Meinung seid, Jahr ist kein \"guter\" random factor, dann nehmt es nicht an random factor ins Modell sondern als erklärende Variable. Begründet das unbedingt in eurer Methodik.\n\nDie Modellformel lautet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoisson_model <- glmer(Total ~ Monat + Ferien + Phase + Wochenende +\n                       tre200jx_scaled + rre150j0_scaled + rre150n0_scaled +\n                         sremaxdv_scaled +\n                         (1 | Jahr), family = poisson, data = umwelt_day)\n\nsummary(poisson_model) # zeigt das Ergebins des Modells\n```\n:::\n\n\nFrage: Was bedeutet \"family = poisson\"?\n\nLöst zuerst Aufgabe 6b bevor ihr alternative (besser passende) Modelle rechnet; das kommt in Aufgabe 6c!\n\n### 6b) Modelldiagnostik\n\n- Prüft ob euer Modell valide ist, mit dem Package DHARMa:\n[Link](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html)\n\nBitte unbedingt die Vignette des DHARMa-Package konsultieren!\n\n__Hinweis:__ Wir verwenden etwas andere Funktionen als in der Vorlesung am morgen. Sie sind unten aufgeführt, und die Funktionen analog zu den Funktionen aus der Vorlesung, aber halt etwas anders.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Residuals werden über eine Simulation auf eine Standard-Skala transformiert und\n# können anschliessend getestet werden. Dabei kann die Anzahl Simulationen eingestellt\n# werden (dauert je nach dem sehr lange)\n\nsimulationOutput <- simulateResiduals(fittedModel = poisson_model, n = 1000)\n\n# plotting and testing scaled residuals\n\nplot(simulationOutput)\n\ntestResiduals(simulationOutput)\n\ntestUniformity(simulationOutput)\n\n# The most common concern for GLMMs is overdispersion, underdispersion and\n# zero-inflation.\n\n# separate test for dispersion\n\ntestDispersion(simulationOutput)\n\n# test for Zeroinflation\n\ntestZeroInflation(simulationOutput)\n\n# Testen auf Multicollinearität (dh zu starke Korrelationen im finalen Modell, zB falls\n# auf Grund der ökologischen Plausibilität stark korrelierte Variablen im Modell)\n# use VIF values: if values less then 5 is ok (sometimes > 10), if mean of VIF values\n# not substantially greater than 1 (say 5), no need to worry.\n\ncar::vif(poisson_model) # funktioniert nicht mit glmmTMB\nmean(car::vif(poisson_model))\n\n# erklaerte varianz\n# The marginal R squared values are those associated with your fixed effects,\n# the conditional ones are those of your fixed effects plus the random effects.\n# Usually we will be interested in the marginal effects.\nperformance::r2(poisson_model)\n```\n:::\n\n\nSind die Voraussetzungen des Modells erfüllt?\n\n\n### 6c) Alternative Modelle\n\nWir sind auf der Suche nach dem minimalen adäquaten Modell. Das ist ein iterativer Prozess. Wir schreiben ein Modell, prüfen ob die Voraussetzungen erfüllt sind und ob die abhängige Variable besser erklärt wird als im Vorhergehenden. Und machen das nochmals und nochmals und nochmals...\n\n- __glmmTMB()__ ist eine sehr schnelle und kompatible Funktion, auch für negativ binomiale Daten. Ich empfehle (spätenstens ab dem exponierten Modell weiter unten) mit ihr zu arbeiten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglmmTMB(Total ~ Monat + Ferien + ..., family =nbinom1,\n                               data = umwelt_day)\n```\n:::\n\n\n- Über __family =__ kann in der Funktion _glmer()__ einiges (aber leider nicht alles so einfach [z.B. negativ binominale Modelle]) angepasst werden: [Link](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/family.html)\n\n- Auch über __link =__ kann man anpassen: [Link](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/make.link.html)\n\n- Unsere (meine) Daten sind negativ binominal verteilt. Daher sollte wir unbedingt ein solches Modell programmieren. --> Funktion __glmer.nb()__\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_model_day <- glmer.nb(Total ~ Monat + Ferien + \n                           ..., \n                         data = umwelt_day)\n\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_model_day <- glmer.nb(Total ~ Monat + Ferien + Phase + Wochenende +\n                             tre200jx_scaled + rre150j0_scaled +\n                             sremaxdv_scaled  +\n                             (1 | Jahr), data = umwelt_day)\n\n```\n:::\n\n\n\n- Falls die Daten exponentiell Verteilt sind, hier der Link zu einem Blogeintrag dazu: [Link](https://stats.stackexchange.com/questions/240455/fitting-exponential-regression-model-by-mle)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglmmTMB((Total + 1) ~ ... \n                         family = Gamma(link = \"log\"), data = umwelt_night)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglmmTMB((Total + 1) ~ Monat + Ferien + Phase + Wochenende +\n                           tre200nx_scaled + I(tre200nx_scaled^2) + rre150n0_scaled +\n                          (1 | Jahr), \n                         family = Gamma(link = \"log\"), data = umwelt_night)\n```\n:::\n\n\n\n- Hypothese: \"Es gehen weniger Leute in den Wald, wenn es zu heiss ist\" --> auf quadratischen Term Temperatur testen! \n__Hinweis:__ ich welchsel hier auf glmmTBM, da diese funktion beudeutend schneller ist und das Ergeniss besser wird (in meinem Fall).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_quad_model_day <- glmmTMB(Total ~ Monat + Ferien + Phase + Wochenende +\n                               tre200jx_scaled + I(tre200jx_scaled^2) + # hier ist der quadratische Term\n                               rre150j0_scaled +  sremaxdv_scaled +\n                               (1 | Jahr), family =nbinom1, # es ist ein negativ binomiales Modell\n                               data = umwelt_day)\n```\n:::\n\n\n\n- Könnte es zwischen einzelnen Variablen zu Interaktionen kommen, die plausible sind? (z. B.: Im Winter hat Niederschlag einen negativeren Effekt als im Sommer, wenn es heiss ist) --> Falls ja: testen!\n\n__Hinweis:__ Interaktionen berechnen ist sehr rechenintensiv. Auch die Interpretation der Resultate wird nicht unbedingt einfacher. Wenn ihr auf Interaktionen testet, dann geht \"langsam\" vor, probiert nicht zu viel auf einmal und verwendet glmmTMB.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  ...\nMonat * rre150j0_scaled +\n  ...\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_quad_int_model_day <- glmmTMB(Total ~  Ferien + Phase + Wochenende +\n                                   Monat * rre150j0_scaled+ tre200jx_scaled + I(tre200jx_scaled^2)  +\n                                   sremaxdv_scaled +\n                                  (1|Jahr), data = umwelt_day)\n```\n:::\n\n\n\n- Habt ihr ein Problem mit zeroinflation? (Dies wisst ihr aus dem Test __testZeroInflation()__ und __testResiduals()__)\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_model_day_zi <- glmmTMB(..., \n                           # The basic glmmTMB fit — a zero-inflated Poisson model with a single zero-\n                           # inflation parameter applying to all observations (ziformula~1)\n                           ziformula=~1,\n                           family = nbinom1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_model_day_zi <- glmmTMB(Total ~ Monat + Phase + Wochenende +\n                             tre200jx_scaled + rre150j0_scaled +\n                             sremaxdv_scaled  +\n                             (1 | Jahr), data = umwelt_day, \n                           # The basic glmmTMB fit — a zero-inflated Poisson model with a single zero-\n                           # inflation parameter applying to all observations (ziformula~1)\n                           ziformula=~1,\n                             family = nbinom1)\n```\n:::\n\n\n- Wenn ihr verschiedene Modelle gerechnet habt, können diese über den AICc verglichen werden. Folgender Code kann dazu genutzt werden:\n\n__Hinweis:__ Nur Modelle mit demselben Datensatz können miteinander verglichen werden. D.h., dass die Modelle mit den originalen Daten nicht mit logarithmiertem oder exponierten Daten verglichen werden können und glmer kann nicht mit glmmTMB verglichen werden. --> Untenstehende Funktion hat für uns also einen eingeschränkten Wert...\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Vergleich der Modellguete mittels AICc\ncand.models <- list()\ncand.models[[1]] <- Tages_Model\ncand.models[[2]] <- Tages_Model_nb\ncand.models[[3]] <- Tages_Model_nb_quad\n\nModnames <- c(\n    \"Tages_Model\", \"Tages_Model_nb\",\n    \"Tages_Model_nb_quad\"\n)\naictab(cand.set = cand.models, modnames = Modnames)\n## K = Anzahl geschaetzter Parameter (2 Funktionsparameter und die Varianz)\n## Delta_AICc <2 = Statistisch gleichwertig\n## AICcWt =  Akaike weight in %\n```\n:::\n\n\n### 6d) (OPTIONAL) Transformationen\n\nBei meinen Daten waren die Modellvoraussetzungen überall mehr oder weniger verletzt. Das ist ein Problem, allerdings auch nicht ein so grosses (man sollte es aber trotzdem ernst nehmen).\nMehr dazu unter:\n\n@schielzeth2020 - Robustness of linear mixed‐effects models to violations of distributional assumptions. \n[Link](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13434)\n\n@lo2015 - To transform or not to transform: using generalized linear mixed models to analyse reaction time data\n[Link](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full)\n\nFalls die Voraussetzungen stark verletzt werden, wäre eine Transformation angezeigt. Mehr dazu unter:\n[Link](https://www.datanovia.com/en/lessons/transform-data-to-normal-distribution-in-r/)\n\n- Wenn ihr das machen wollt, berechnet zuerst den skewness coefficient \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"moments\")\nskewness(umwelt_day$Anzahl_Total)\n## A positive value means the distribution is positively skewed (rechtsschief).\n## The most frequent values are low; tail is toward the high values (on the right-hand side)\n```\n:::\n\n\n- Welche Transformation kann angewandt werden?\n- Was spricht gegen eine Transformation (auch im Hinblick zur Visualisierung und Interpretation)? Was spricht dafür?\n\n\n\n### 6c) Modelle für DUSKDAWN und NIGHT\n\nIhr habt bereits sehr viel Arbeit in die Suche nach dem besten Modell für den Tag investiert und das nun gefunden. In wir interessieren uns nun dafür, ob die Effekte während der Dämmerung und der Nacht gleich oder verschieden sind. \n\n- Sucht analog dem vorgehen am Tag auch für die Dämmerung und die Nacht nach den dort besten Modellen.\n\n__Hinweis:__ ihr müsst nicht mehr alles komplett duchspielen. Das Modell, welches am Tag gut war, ist sehr wahrscheinlich auch bei den anderen Datensätzen recht gut. Startet also mit einer ähnlichen spezifikation wie beim besten Modell für den Tag.\n\n\n\n### 6d) Exportiere die Modellresultate (der besten Modelle)\n\nWelches ist euer bestes Modell für den Tag? \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mein bestes Modell ist:\n\n# interaktion zero inflation\n# \"Ferien\" not sig, therefore exclude\nnb_int_model_day_zi <- glmmTMB(Total ~ Phase + Wochenende +\n                             Monat * rre150j0_scaled + tre200jx_scaled + I(tre200jx_scaled^2) +\n                             sremaxdv_scaled +\n                             (1 | Jahr), data = umwelt_day, \n                           # The basic glmmTMB fit — a zero-inflated Poisson model with a single zero-\n                           # inflation parameter applying to all observations (ziformula~1)\n                           ziformula=~1,\n                           family = nbinom1)\n```\n:::\n\n\n\nModellresultate können mit __summary()__ angezeigt werden. Ich verwende aber lieber die Funktion __tab_model()__! Die Resultate werden gerundet und praktisch im separaten Fenster angezeigt. Von dort kann man sie via copy + paste ins (z.B.) Word bringen. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(MODELLNAME, \n          transform = NULL, # To plot the estimates on the linear scale, use transform = NULL.\n          show.se = TRUE) # zeige die Standardabweichung\n## The marginal R squared values are those associated with your fixed effects,\n## the conditional ones are those of your fixed effects plus the random effects.\n## Usually we will be interested in the marginal effects.\n```\n:::\n\n\n\n## Aufgabe 7: Modellvisualisierung\n\n- Visualisiert die (signifikanten) Ergebnisse eures Modells. Sabrina Harsch hat im HS21 eine sehr nützliche Funktion dafür geschriben (welche ich etwas weiter ausgebaut habe). Es gibt für die kontinuierlichen Variablen und für die diskreten Variablen je eine seperate Funktion und das jeweils für die drei Tageszeiten (die Linien der Plots sind anders eingefärbt).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# schreibe fun fuer continuierliche var\nrescale_plot_num_day <- function(input_df, input_term, unscaled_var, scaled_var, num_breaks, x_lab, y_lab, x_scaling, x_nk) {\n  plot_id <- plot_model(input_df, type = \"pred\", terms = input_term, axis.title = \"\", title = \"\", color = \"orangered\")\n  labels <- round(seq(floor(min(unscaled_var)), ceiling(max(unscaled_var)), length.out = num_breaks + 1) * x_scaling, x_nk)\n  \n  custom_breaks <- seq(min(scaled_var), max(scaled_var), by = ((max(scaled_var) - min(scaled_var)) / num_breaks))\n  custom_limits <- c(min(scaled_var), max(scaled_var))\n  \n  plot_id <- plot_id +\n    scale_x_continuous(breaks = custom_breaks, limits = custom_limits, labels = c(labels), labs(x = x_lab)) +\n    scale_y_continuous(labs(y = y_lab), limits = c(0, 170)) +\n    theme_classic(base_size = 20)\n  \n  return(plot_id)\n}\n\nrescale_plot_num_night <- function(input_df, input_term, unscaled_var, scaled_var, num_breaks, x_lab, y_lab, x_scaling, x_nk) {\n  plot_id <- plot_model(input_df, type = \"pred\", terms = input_term, axis.title = \"\", title = \"\", color = \"darkblue\")\n  labels <- round(seq(floor(min(unscaled_var)), ceiling(max(unscaled_var)), length.out = num_breaks + 1) * x_scaling, x_nk)\n  \n  custom_breaks <- seq(min(scaled_var), max(scaled_var), by = ((max(scaled_var) - min(scaled_var)) / num_breaks))\n  custom_limits <- c(min(scaled_var), max(scaled_var))\n  \n  plot_id <- plot_id +\n    scale_x_continuous(breaks = custom_breaks, limits = custom_limits, labels = c(labels), labs(x = x_lab)) +\n    scale_y_continuous(labs(y = y_lab), limits = c(0, 20)) +\n    theme_classic(base_size = 20)\n  \n  return(plot_id)\n}\n\nrescale_plot_num_duskdawn <- function(input_df, input_term, unscaled_var, scaled_var, num_breaks, x_lab, y_lab, x_scaling, x_nk) {\n  plot_id <- plot_model(input_df, type = \"pred\", terms = input_term, axis.title = \"\", title = \"\", color = \"mediumvioletred\")\n  labels <- round(seq(floor(min(unscaled_var)), ceiling(max(unscaled_var)), length.out = num_breaks + 1) * x_scaling, x_nk)\n  \n  custom_breaks <- seq(min(scaled_var), max(scaled_var), by = ((max(scaled_var) - min(scaled_var)) / num_breaks))\n  custom_limits <- c(min(scaled_var), max(scaled_var))\n  \n  plot_id <- plot_id +\n    scale_x_continuous(breaks = custom_breaks, limits = custom_limits, labels = c(labels), labs(x = x_lab)) +\n    scale_y_continuous(labs(y = y_lab), limits = c(0, 15)) +\n    theme_classic(base_size = 20)\n  \n  return(plot_id)\n}\n\n\n\n# schreibe fun fuer diskrete var\nrescale_plot_fac_day <- function(input_df, input_term, unscaled_var, scaled_var, num_breaks, x_lab, y_lab, x_scaling, x_nk) {\n  plot_id <- plot_model(input_df, type = \"pred\", terms = input_term, axis.title = \"\", title = \"\", color = \"orangered\")\n  \n  plot_id <- plot_id +\n    scale_y_continuous(labs(y = y_lab), limits = c(0, 170)) +\n    theme_classic(base_size = 20) +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n  \n  return(plot_id)\n}\n\nrescale_plot_fac_night <- function(input_df, input_term, unscaled_var, scaled_var, num_breaks, x_lab, y_lab, x_scaling, x_nk) {\n  plot_id <- plot_model(input_df, type = \"pred\", terms = input_term, axis.title = \"\", title = \"\", color = \"darkblue\")\n  \n  plot_id <- plot_id +\n    scale_y_continuous(labs(y = y_lab), limits = c(0, 20)) +\n    theme_classic(base_size = 20) +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n  \n  return(plot_id)\n}\n\nrescale_plot_fac_duskdawn <- function(input_df, input_term, unscaled_var, scaled_var, num_breaks, x_lab, y_lab, x_scaling, x_nk) {\n  plot_id <- plot_model(input_df, type = \"pred\", terms = input_term, axis.title = \"\", title = \"\", color = \"mediumvioletred\")\n  \n  plot_id <- plot_id +\n    scale_y_continuous(labs(y = y_lab), limits = c(0, 15)) +\n    theme_classic(base_size = 20) +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n  \n  return(plot_id)\n}\n```\n:::\n\n\n\nNun können die einzelnen Variabeln aus den besten Modellen in der Funktion jeweils für die Plots angepasst werden:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Tagesmaximaltemperatur\ninput_df <- nb_int_model_day_zi\ninput_term <- \"tre200jx_scaled [all]\"\nunscaled_var <- umwelt_day$tre200jx\nscaled_var <- umwelt_day$tre200jx_scaled\nnum_breaks <- 10\nx_lab <- \"Temperatur [°C]\"\ny_lab <- \"Fussgänger:innen pro Tag\"\nx_scaling <- 1 # in prozent\nx_nk <- 0 # x round nachkommastellen\n\n\np_temp <- rescale_plot_num_day(\n  input_df, input_term, unscaled_var, scaled_var, num_breaks,\n  x_lab, y_lab, x_scaling, x_nk\n)\np_temp\n```\n\n::: {.cell-output-display}\n![](7_Multivariate_Modelle_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## Wochentag \ninput_df <- nb_int_model_day_zi\ninput_term <- \"Wochenende [all]\"\nunscaled_var <- umwelt_day$Wochenende\nscaled_var <- umwelt_day$Wochenende\nnum_breaks <- 10\nx_lab <- \"Wochentag\"\ny_lab <- \"Fussgänger:innen pro Tag\"\nx_scaling <- 1 # in prozent\nx_nk <- 0 # x round nachkommastellen\n\n\np_wd <- rescale_plot_fac_day(\n  input_df, input_term, unscaled_var, scaled_var, num_breaks,\n  x_lab, y_lab, x_scaling, x_nk)\np_wd\n```\n\n::: {.cell-output-display}\n![](7_Multivariate_Modelle_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n- Exportiert die Ergebnisse via __ggsave()__.\n\n__Hinweis:__ damit unsere Plots verglichen werden können, sollen sie alle dieselbe Skalierung (limits) auf der y-Achse haben. Das wird erreicht, indem man bei jedem Plot die __limits__ in __scale_y_continuous()__ gleichsetzt.\n\n__Hinweis:__ Es könnten auch interaction-plots erstellt werden: [Link](https://cran.r-project.org/web/packages/sjPlot/vignettes/plot_interactions.html)\n\n## Abschluss\n\nNun habt ihr verschiedenste Ergebnisse vorliegen. In einem wissenschaftlichen Bericht sollen aber niemals alle Ergebnisse abgebildet werden. Eine Faustregel besagt, dass nur signifikante Ergebnisse visualisiert werden. Entscheidet euch daher, was ihr in eurem Bericht abbilden wollt und was lediglich besprochen werden soll.\n\nStellt im Bericht die Ergebnisse des Tages, der Dämmerung und der Nacht gegenüber und beschreibt die Gemeinsamkeiten und Unterschieden. Behaltet dabei immer die Forschungsfragen in Erinnerung.\n",
    "supporting": [
      "7_Multivariate_Modelle_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}