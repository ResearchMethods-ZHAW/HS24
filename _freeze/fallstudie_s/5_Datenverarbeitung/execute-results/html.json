{
  "hash": "76cb8139d81a7318f8381a28f6a7bd4f",
  "result": {
    "markdown": "---\ndate: 2023-10-17\nlesson: Datenvorverarbeitung\nthema: Daten so aufbereiten, dass Analysen durchgeführt werden können\nindex: 2\nexecute: \n  echo: true   # set to true to show musterlösung\n  output: false\ncode-fold: true # set false to show all code\ncode-summary: \"Musterlösung\"\nknitr:\n  opts_chunk: \n    collapse: true\n---\n\n\n# Datenverarbeitung\n\n\n\n\n\n\n## Aufgabe 1: Zähldaten\n\n### 1a)\n\nDie Projektstruktur steht. Nun können die Daten eingelesen und die nötigen Datentypen definiert werden. \n\nLädt die Daten zuerst von Moodle herunter.\n\nHinweise: \n\n- Siehe [Einführung] für den Standort der __Zähler 211 und 502__. \n\n- Alle für die Fallstudie Profil S benötigten Daten könnt ihr unter folgendem  [Link](https://moodle.zhaw.ch/mod/folder/view.php?id=956254) herunterladen.\n\n1. Zähldaten zu eurem Standort (211_sihlwaldstrasse_2017_2022.csv, 502_sihluferweg_2016_2022.csv)\n2. Meteodaten (order_105742_data.txt)\n\n\nDie Zähldaten des WPZ wurden vorgängig bereinigt (z.B. wurden Stundenwerte entfernt, an denen am Zähler Wartungsarbeiten stattgefunden haben). Das macht es für uns einfach, denn wir können die Daten ohne vorgängige Bereinigung einlesen. Behaltet aber im Hinterkopf, dass die Datenaufbereitung, die Datenbereinigung mit viel Aufwand verbunden ist.\n\n- Lest die Zählaten ein, speichert ihn unter der Variable __depo__ und sichtet den Datensatz (z.B. str(), head(), view() usw.).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Speicherort sowie Dateiname anpassen\ndepo <- read_delim(\"./HIER RELATIVEN DATEIPFAD EINGEBEN\", \"HIER SEPERATOR EINGEBEN\")\n```\n:::\n\n\n__Hinweis:__ Im Stundenformat zeigen die Werte bei 11:00 die Zähldaten zwischen 11:00 bis 12:00 Uhr.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lese die Daten ein\ndepo <- read_delim(\"datasets/fallstudie_s/WPZ/211_sihlwaldstrasse_2017_2022.csv\", \";\")\n\n# erstes Sichten und anpassen der Datentypen\nstr(depo)\n```\n:::\n\n\n\n### 1b) \n\n- Nun muss das Datum als solches definiert werden. Welches Format hat es (im Code: format = \"HIER DATUMSFORMAT\")?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndepo <- depo |>\n  mutate(\n    Datetime = as.POSIXct(DatumUhrzeit, format = \"HIER STEHT DAS DATUMSFORMAT\", tz = \"CET\"),\n    # nun schreiben wir uns das Datum in eine seperate Spalte\n    Datum = as.Date(Datetime)\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# hier der code mit dem richtigen Format\ndepo <- depo |>\n  mutate(\n    Datetime = as.POSIXct(DatumUhrzeit, format = \"%d.%m.%Y %H:%M\", tz = \"CET\"),\n    Datum = as.Date(Datetime)\n  )\n```\n:::\n\n\n### 1c) \n\nIhr könnt selbst wählen, ob ihr Fussgänger:innen oder Fahrräder untersuchen wollt (je nachdem ob sie in eurem Datensatz vorhanden sind).\n\n- Entfernt die überflüssigen Spalten aus dem Datensatz. Ich schlage vor, dass ihr dafür den Befehl dplyr::select() verwendet.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# In dieser Auswertung werden nur Personen zu Fuss betrachtet!\n# it select werden spalten ausgewaehlt oder eben fallengelassen\ndepo <- depo |>\n  dplyr::select(-c(Velo_IN, Velo_OUT, Zeit, DatumUhrzeit))\n```\n:::\n\n\n\n### 1d) \n\n- Berechnen des Totals (IN + OUT), da dieses in den Daten nicht vorhanden ist (wiederum mit piping). \n\nTipp: Wenn man R sagt: \"addiere mir Spalte x mit Spalte y\", dann macht R das für alle Zeilen in diesen zwei Spalten. Wenn man nun noch sagt: \"speichere mir das Ergebnis dieser Addition in einer neuen Spalte namens __Total__\", dann hat man die Aufgabe bereits gelöst. Arbeitet mit __mutate()__).\n\n__Hinweis:__ Ihr habt das auch schon in Kapitel [Einführung und Installation] gemacht.\n\n- Entfernt nun alle NA-Werte mit __na.omit()__.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Berechnen des Totals, da dieses in den Daten nicht vorhanden ist\ndepo <- depo |>\n  mutate(Total = Fuss_IN + Fuss_OUT)\n\n# Entferne die NA's in dem df.\ndepo <- na.omit(depo)\n```\n:::\n\n\n\n\n## Aufgabe 2: Meteodaten\n\n### 2a) \n\n- Lest die Meteodaten ein und speichert sie unter __meteo__.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Einlesen\nmeteo <- read_delim(\"datasets/fallstudie_s/WPZ/order_105742_data.txt\", \";\")\n```\n:::\n\n\n### 2b) \n\n- Auch hier müssen die Datentypen manuell gesetzt werden. \n\nTipp: Das Datum wird als Integer erkannt. Zuerst muss es in Text umgewandelt werden aus dem dann das eigentliche Datum herausgelesen werden kann. Das ist mühsam - darum hier der Code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeteo <- mutate(meteo, time = as.Date(as.character(time), \"%Y%m%d\"))\n```\n:::\n\n\nDie Zeitangaben sind in UTC: \n00:40 UTC = 02:40 Sommerzeit = 01:40 Winterzeit, Beispiel: 13 = beinhaltet Messperiode von 12:01 bis 13:00\n\n--> Da wir mit Tageshöchstwerten oder -summen rechnen, können wir zum Glück ignorieren, dass das nicht mit den Daten der Zählstellen übereinstimmt. Learning: es ist zentral immer die Metadaten zu checken.\n\n__Hinweis__ Was ist eigentlich Niederschlag:\n\n[Link Meteo Schweiz](https://www.meteoschweiz.admin.ch/home/wetter/wetterbegriffe/niederschlag.html)\n\n- Werden den anderen Spalten die richtigen Typen zugewiesen? Falls nicht, ändert die Datentypen.\n\n- Nun schneiden wir den Datensatz auf die Untersuchungsdauer zu.\n\n- Dann müssen auch hier alle nicht verfügbare Werte (NA's) herausgefiltert werden.\n\n- Prüft nun, wie die Struktur des data.frame (df) aussieht und ob alle NA Werte entfernt wurden (sum(is.na(df$Variable))). Stimmen alle Datentypen?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Die eigentlichen Messwerte sind alle nummerisch\nmeteo <- meteo |>\n    mutate(\n        tre200nx = as.numeric(tre200nx),\n        tre200jx = as.numeric(tre200jx),\n        rre150n0 = as.numeric(rre150n0),\n        rre150j0 = as.numeric(rre150j0),\n        sremaxdv = as.numeric(sremaxdv)\n    ) |>\n    filter(time >= depo_start, time <= depo_end) # schneide dann auf Untersuchungsdauer\n\n# Was ist eigentlich Niederschlag:\n# https://www.meteoschweiz.admin.ch/home/wetter/wetterbegriffe/niederschlag.html\n\n# Filtere Werte mit NA\nmeteo <- na.omit(meteo)\n# Pruefe ob alles funktioniert hat\nstr(meteo)\nsum(is.na(meteo)) # zeigt die Anzahl NA's im data.frame an\n```\n:::\n\n\n\n## Aufgabe 3: Datenvorverarbeitung (Mutationen)\n\n### 3a) \n\nJetzt fügen wir viele Convinience Variabeln hinzu. Wir brauchen:\n\n1. Wochentag; der Befehl dazu ist __wday()__. Danach als Faktor speichern.\n2. Werktag oder Wochenende als Faktor. Der Code dazu könnte so aussehen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  ...|>\n  mutate(Wochenende = ifelse(Wochentag %in% c(6,7), \"Wochenende\", \"Werktag\")) |>\n  mutate(Wochenende = as.factor(Wochenende)) |>\n  ...\n```\n:::\n\n\nje als Faktor: \n3. Kalenderwoche: __isoweek()__\n4. Monat: __month()__\n5. Jahr: __year()__\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndepo <- depo |>\n  # wday sortiert die Wochentage automatisch in der richtigen Reihenfolge\n  mutate(\n    Wochentag = wday(Datetime, week_start = 1),\n    Wochentag = factor(Wochentag),\n    # Werktag oder Wochenende hinzufuegen\n    Wochenende = ifelse(Wochentag %in% c(6, 7), \"Wochenende\", \"Werktag\"),\n    Wochenende = as.factor(Wochenende),\n    # Kalenderwoche hinzufuegen\n    KW = isoweek(Datetime),\n    KW = factor(KW),\n    # monat und Jahr\n    Monat = month(Datetime),\n    Monat = factor(Monat),\n    Jahr = year(Datetime),\n    Jahr = factor(Jahr))\n```\n:::\n\n\n\nDies machen wir auch mit dem \"meteo\" Datensatz.\n\n- Wiederum bitte Wochentag, Werktag oder Wochenende, Kalenderwoche, Monat und Jahr. Ebenfalls alles als Faktor speichern.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wir gruppieren die Meteodaten noch nach Kalenderwoche und Werktag / Wochenende\n# Dafür brauchen wir zuerst diese als Convenience Variablen\nmeteo <- meteo |>\n  # wday sortiert die Wochentage automatisch in der richtigen Reihenfolge\n  mutate(\n    Wochentag = wday(time, week_start = 1),\n    Wochentag = factor(Wochentag),\n    # Werktag oder Wochenende hinzufuegen\n    Wochenende = ifelse(Wochentag %in% c(6, 7), \"Wochenende\", \"Werktag\"),\n    Wochenende = as.factor(Wochenende),\n    # Kalenderwoche hinzufuegen\n    KW = isoweek(time),\n    KW = factor(KW),\n    # monat und Jahr\n    Monat = month(time),\n    Monat = factor(Monat),\n    Jahr = year(time),\n    Jahr = factor(Jahr))\n\n```\n:::\n\n\n- Später werden wir nicht nur Analysen pro Tag machen, sondern auch zusammengefasst nach Woche. Dafür müssen wir nun den meteo-Datensaz gruppieren und den mean berechnen. Hier der Code dazu, wie das aussehen könnte:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeteo_day <- meteo |>\n  group_by(Jahr, Monat, KW, Wochenende) |>\n  summarise(\n    tre200nx = mean(tre200nx),\n    tre200jx = mean(tre200jx),\n    rre150n0 = mean(rre150n0),\n    rre150j0 = mean(rre150j0),\n    sremaxdv= mean(sremaxdv))\n```\n:::\n\n\n\nWieder zurück zum Depo-Datensazt.\n\nIch mache den folgenden Punkt nachgelagert, da zu viele Operationen in einem Schritt auch schon mal etwas durcheinander erzeugen können.\n\nPhase Covid (Code untenstehend). Wir definieren 5 Phasen: \n\n  - von Anfang Untersuchungsperiode bis 1 Jahr vor Lockdown 1\n  - Lockdown 1\n  - zwischen den Lockdowns\n  - Lockdown 2\n  - Ende 2. Lockdown bis Ende Untersuchungsperiode\n\n- Wir packen alle Phasen (normal, die beiden Lockdowns und Covid aber ohne Lockdown) in eine Spalte --> long-format ist schöner (und praktischer für das plotten) als wide-format.\n\n- Später im multivariaten Modell werden die Levels der Variablen (z.B. bei der Phase Covid: Pre, Normal, Lockdown 1 und 2, Covid) per \"default\" alphabetisch geordnet und die Effektstärken der einzelnen Levels gegenüber dem ersten Level gerechnet. Das macht wenig Sinn, den die Levels sind nicht alphabetisch, sondern gemäss der Liste oben. Das passen wir ebenfalls an.\n\n- Hier der Code dazu:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndepo <- depo |>\n    mutate(Phase = case_when(\n        Datetime < lock_1_start ~ \"Pre\",\n        Datetime >= lock_1_start & Datetime <= lock_1_end ~ \"Lockdown_1\",\n        Datetime > lock_1_end & Datetime < lock_2_start ~ \"inter\",\n        Datetime >= lock_2_start & Datetime <= lock_2_end ~ \"Lockdown_2\",\n        Datetime > lock_2_end ~ \"Post\"\n    ))\n\n# hat das gepklappt?!\nunique(depo$Phase)\n\ndepo <- depo |>\n    # mit factor() koennen die levels direkt einfach selbst definiert werden.\n    # wichtig: speizfizieren, dass aus R base, ansonsten kommt es zu einem\n    # mix-up mit anderen packages\n    mutate(Phase = base::factor(Phase, levels = c(\"Pre\", \"Lockdown_1\", \"Inter\", \"Lockdown_2\", \"Post\")))\n\nstr(depo)\n```\n:::\n\n\nNeben dem Lockdown können auch die Schulferien einen Einfluss auf die Besuchszahlen haben. Wir haben die Schulferien bereits als .csv eingelesen. Allerdings können wir die Schulferien nicht mit der case_when()-Funktion zuweisen, da diese mit dieser Funktion alle  Vektoren im Datensatz \"schulferien\" verglichen werden, und nicht elementweise für jede Zeile im \"depo\"-Datensatz. Dies führt dazu, dass die Bedingungen nur einmal überprüft werden und dann auf den gesamten Vektor angewendet werden, anstatt Zeile für Zeile. \n\n- Weil dies etwas kompliziert ist, hier eine Funktion zur Zuweisung der Ferien, welche ihr kopieren könnt:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# schreibe nun eine Funktion zur zuweisung Ferien. WENN groesser als start UND kleiner als\n# ende, DANN schreibe ein 1\nfor (i in 1:nrow(schulferien)) {\n  depo$Ferien[depo$Datum >= schulferien[i, \"Start\"] & depo$Datum <= schulferien[i, \"Ende\"]] <- 1\n}\ndepo$Ferien[is.na(depo$Ferien)] <- 0\n\n# als faktor speichern\ndepo$Ferien <- factor(depo$Ferien)\n```\n:::\n\n\n\n### 3b)\n\n- Nun soll noch die volle Stunde als Integer im Datensatz stehen. Macht das mit dem Befehl __hour()__\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fuer einige Auswertungen muss auf die Stunden als nummerischer Wert zurueckgegriffen werden\ndepo$Stunde <- hour(depo$Datetime)\n# hour gibt uns den integer\ntypeof(depo$Stunde)\n```\n:::\n\n\n### 3c) \n\nDie Daten wurden durch den WPZ kalibriert (Kommastellen). \n\n- Rundet sie auf 0 Nachkommastellen (Ganzzahl; unser Modell kann nicht mit Kommazahlen in der ahbängigen Variable umgehen). Der Befeht lautet __round()__\n\n- Definiert sie sicherheitshalber als Integer\n\n- Macht das für IN, OUT und Total.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndepo$Total <- round(depo$Total, digits = 0)\ndepo$Fuss_IN <- round(depo$Fuss_IN, digits = 0)\ndepo$Fuss_OUT <- round(depo$Fuss_OUT, digits = 0)\n```\n:::\n\n\n\n### 3d) Tageszeit\n\nWir setzen den Fokus unserer Untersuchung auf die Veränderung der Besuchszahlen in der Abend- und Morgendämmerung sowie der Nacht. Dafür müssen wir diese tageszeitliche Einteilung der Daten erst machen. Da dies über den Umfang dieser Fallstudie geht, liefere ich euch hier den Code dazu.\n\nDie wichtigsten Punkte:\n\n- Die Tageslänge wurde für den Standort Zürich (Zeitzone CET) mit dem Package \"suncalc\" berechnet. Dabei wurden Sommer- und Winterzeit berücksichtigt.\n- Die Einteilung der Tageszeit beruht auf dem Start und dem Ende der astronomischen Dämmerung sowie der Golden Hour. Der Morgen und der Abend wurden nach dieser Definition berechnet und um je eine Stunde Richtung Tag verlängert. \n\n- Untenstehenden Code könnt ihr einfach kopieren.\n\nHinweis: damit __case_when()__ funktioniert, müsst ihr  dplyr Version als 1.1.1 oder neuer haben.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Einteilung Standort Zuerich\nLatitude <- 47.38598\nLongitude <- 8.50806\n\n# Start und das Ende der Sommerzeit:\n# https://www.schulferien.org/schweiz/zeit/zeitumstellung/\n\n\n# Welche Zeitzone haben wir eigentlich?\n# Switzerland uses Central European Time (CET) during the winter as standard time,\n# which is one hour ahead of Coordinated Universal Time (UTC+01:00), and\n# Central European Summer Time (CEST) during the summer as daylight saving time,\n# which is two hours ahead of Coordinated Universal Time (UTC+02:00).\n# https://en.wikipedia.org/wiki/Time_in_Switzerland\n\n# Was sind Astronomische Dämmerung und Golden Hour ueberhaupt?\n# https://sunrisesunset.de/sonne/schweiz/zurich-kreis-1-city/\n# https://www.rdocumentation.org/packages/suncalc/versions/0.5.0/topics/getSunlightTimes\n\n# Wir arbeiten mit folgenden Variablen:\n# \"nightEnd\" : night ends (morning astronomical twilight starts)\n# \"goldenHourEnd\" : morning golden hour (soft light, best time for photography) ends\n# \"goldenHour\" : evening golden hour starts\n# \"night\" : night starts (dark enough for astronomical observations)\n\nlumidata <-\n    getSunlightTimes(\n        date = seq.Date(depo_start, depo_end, by = 1),\n        keep = c(\"nightEnd\", \"goldenHourEnd\", \"goldenHour\", \"night\"),\n        lat = Latitude,\n        lon = Longitude,\n        tz = \"CET\"\n    ) |>\n    as_tibble()\n\n# jetzt haben wir alle noetigen Angaben zu Sonnenaufgang, Tageslaenge usw.\n# diese Angaben koennen wir nun mit unseren Zaehldaten verbinden:\ndepo <- depo |>\n    left_join(lumidata, by = c(Datum = \"date\"))\n\ndepo <- depo |>\n    mutate(Tageszeit = case_when(\n        Datetime >= nightEnd & Datetime <= goldenHourEnd ~ \"Morgen\",\n        Datetime > goldenHourEnd & Datetime < goldenHour ~ \"Tag\",\n        Datetime >= goldenHour & Datetime <= night ~ \"Abend\",\n        .default = \"Nacht\"\n    )) |>\n    mutate(Tageszeit = factor(Tageszeit, levels = c(\"Morgen\", \"Tag\", \"Abend\", \"Nacht\"), ordered = TRUE))\n\n# behalte die relevanten Var\ndepo <- depo |> dplyr::select(-nightEnd, -goldenHourEnd, -goldenHour, -night, -lat, -lon)\n\n# Plotte zum pruefn ob das funktioniert hat\nggplot(depo, aes(y = Datetime, color = Tageszeit, x = Stunde)) +\n    geom_jitter() +\n    scale_color_manual(values = mycolors)\n\nsum(is.na(depo))\n\n# bei mir hat der Zusatz der Tageszeit noch zu einigen NA-Wertren gefueht.\n# Diese loesche ich einfach:\ndepo <- na.omit(depo)\n# hat das funktioniert?\nsum(is.na(depo))\n```\n:::\n\n\n\n## Aufgabe 4: Aggregierung der Stundendaten\n\n### 4a) \n\nUnsere Daten liegen im Stundenformat vor. Für einige Auswertungen müssen wir aber auf ganze Tage zurückgreifen können. \n\n- Die Stundendaten müssen zu ganzen Tagen aggregiert werden. Macht das wiederum einer Pipe. Bezieht folgende Gruppierungen (__group_by()__) mit ein: __Datum, Wochentag, Wochenende, KW, Monat, Jahr, Phase__. Summiert die Zählmengen separat (Total, IN, OUT) auf und speichert das Resultat unter __depo_d__.\n\nTipp: Wenn man die Convinience Variablen als grouping variable einspeisst, dann werden sie in das neue df übernommen und müssen nicht nochmals hinzugefügt werden\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndepo_d <- depo |> \n  group_by(VARIABLE1, VARIABLE2, ...) |>   # Gruppieren nach den Variablen\n  summarise(Total = sum(Fuss_IN + Fuss_OUT),# Berechnen der gewünschten Werte\n            Fuss_IN = sum(Fuss_IN),\n            ...\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# hier werden also pro Nutzergruppe und Richtung die Stundenwerte pro Tag aufsummiert\ndepo_d <- depo |>\n    group_by(Datum, Wochentag, Wochenende, KW, Monat, Jahr, Phase) |>\n    summarise(\n        Total = sum(Fuss_IN + Fuss_OUT),\n        Fuss_IN = sum(Fuss_IN),\n        Fuss_OUT = sum(Fuss_OUT)\n    )\n# Wenn man die Convinience Variablen als grouping variable einspeisst, dann werden sie in\n# das neue df uebernommen und muessen nicht nochmals hinzugefuegt werden\n# pruefe das df\nhead(depo_d)\n```\n:::\n\n\n\n- Erstellt nun einen Datensatz depo_daytime, in welchem ihr gruppiet nach:\na) Jahr\nb) Monat\nc) Kalenderwoche\nd) Phase\ne) Ferien\nf) Wochenende oder Werktag\ng) Tageszeit\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# nun gruppieren wir nicht nur nach Tag sondern auch noch nach Tageszeit\ndepo_daytime <- depo |>\n  group_by(Jahr, Monat, KW, Phase, Ferien, Wochenende, Tageszeit) |>\n  summarise(\n    Total = sum(Fuss_IN + Fuss_OUT),\n    Fuss_IN = sum(Fuss_IN),\n    Fuss_OUT = sum(Fuss_OUT))\n```\n:::\n\n\n- Weiter benötigen wir für für die Berechnung der Verteilung der Besuchenden über den Tag die durchschnittliche Besucheranzahl pro Stunde (mean), unterteilt nach Tageszeit und Phase __(Gruppierungen Tageszeit, Phase__). Speichert das unter \"mean_phase_d\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_phase_d <- depo_daytime |>\n  group_by(Phase, Tageszeit) |>\n  summarise(\n    Total = mean(Total),\n    IN = mean(Fuss_IN),\n    OUT = mean(Fuss_OUT))\n```\n:::\n\n\n\n### 4b)\n\n- Aggregiere die Stundenwerte nach dem Monat (Gruppierungen __Monat, Jahr__) und speichert das neue df unter depo_m.\n\nTipp: Braucht wiederum __group_by()__ und __summarise()__. Nun brauchen wir nur noch das Total, keine Richtungstrennung mehr.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndepo_m <- depo |>\n    group_by(Jahr, Monat) |>\n    summarise(Total = sum(Total))\n```\n:::\n\n\n\n- Fügt den neu erstellten df eine Spalte mit Jahr + Monat hinzu. Hier der fertige Code dazu:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndepo_m <- depo_m |>\n    mutate(\n        Ym = paste(Jahr, Monat), # und mache eine neue Spalte, in der Jahr und\n        Ym = lubridate::ym(Ym)\n    ) # formatiere als Datum\n```\n:::\n\n\n- Wiederholt diesen Schritt, diesmal aber mit der Gruppierung \"Tageszeit\" neben \"Jahr\" und \"Monat\" und speichert das Resultat unter \"depo_m_daytime\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gruppiere die Werte nach Monat und TAGESZEIT\ndepo_m_daytime <- depo |>\n    group_by(Jahr, Monat, Tageszeit) |>\n    summarise(Total = sum(Total))\n# sortiere das df aufsteigend (nur das es sicher stimmt)\n\ndepo_m_daytime <- depo_m_daytime |>\n    mutate(\n        Ym = paste(Jahr, Monat), # und mache eine neue Spalte, in der Jahr und\n        Ym = lubridate::ym(Ym)\n    ) # formatiere als Datum\n```\n:::\n\n\n\n### 4c)\n\nMacht euch mit den Daten vertraut. Plottet sie, seht euch die df's an, versteht, was sie representieren.\n\nZ.B. sind folgende Befehle und Plots wichtig:\n\n- str()\n- summarize()\n- head()\n\n- Scatterplot, x = Datum, y = Anzahl pro Zeiteinheit\n- Histrogram\n- usw.\n\n__Hinweis:__ Geht noch nicht zu weit mit euren Plots. Die Idee ist, dass man sich einen Überblick über die Daten verschafft und noch keine \"analysierenden\" Plots erstellt.\n\nNachdem nun alle Daten vorbereitet sind folgt im nächsten Schritt die deskriptive Analyse.\n",
    "supporting": [
      "5_Datenverarbeitung_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}