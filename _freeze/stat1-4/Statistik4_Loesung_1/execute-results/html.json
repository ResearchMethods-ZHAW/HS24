{
  "hash": "2ef1c985c5c222db01eb99d78450cfa7",
  "result": {
    "markdown": "---\ndate: 2023-11-07\nlesson: Stat4\nthema: Komplexere Regressionsmethoden\nindex: 3\nformat:\n  html:\n    code-tools:\n      source: true\nknitr:\n    opts_chunk:\n        collapse: false\n---\n\n\n# Stat4: Lösung 4.1\n \n- Download dieses Lösungsscript via \"\\</\\>Code\" (oben rechts)\n- [Lösungstext als Download](Statistik_Loesung_4.1.pdf)\n\n## Musterlösung Übung 4.1: Nicht-lineare Regression\n\n**Übungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird)**\n\n- Laden Sie den Datensatz Curonia_spit.xlsx. Dieser enthält gemittelte            \n  Pflanzenartenzahlen (Species.richness) von geschachtelten Plots \n  (Vegetationsaufnahmen) der Pflanzengesellschaft Lolio-Cynosuretum im\n  Nationalpark Kurische Nehrung (Russland) auf Flächengrössen (Area) von 0.0001 bis\n  900 m².\n- **Ermitteln Sie den funktionellen Zusammenhang, der die Zunahme der Artenzahl mit der Flächengrösse am besten beschreibt. Berücksichtigen Sie dabei mindestens die Potenzfunktion (power function), die logarithmische Funktion (logarithmic function) und eine Funktion mit Sättigung (saturation, asymptote) Ihrer Wahl**\n- Bitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu\n  diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie\n  Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre\n  Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere\n  Vorgehen dokumentieren.\n- Dieser Ablauf sollte insbesondere beinhalten:\n    - Überprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n)\n      und welches die unabängige(n) Variablen\n    - Explorative Datenanalyse, um zu sehen, ob eine nicht-lineare Regression überhaupt\n      nötig ist und ob evtl. Dateneingabefehler vorliegen vorgenommen werden sollten\n    - Definition von mindestens drei nicht-linearen Regressionsmodellen\n    - Selektion des/der besten Models/Modelle\n    - Durchführen der Modelldiagnostik für die Modelle in der engeren Auswahl, um zu\n      entscheiden, ob das gewählte Vorgehen korrekt war oder ggf. angepasst werden\n      muss\n    - Generieren aller Zahlen, Statistiken und Tabellen, die für eine wiss.\n      Ergebnisdarstellung benötigt werden\n- Formulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl.\n  adäquaten Abbildungen) zu dieser Untersuchung in der Form einer\n  wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je\n  einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und\n  Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige\n  Redundanz dagegen vermieden werden.\n- **Zu erstellen sind (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).**\n\n### Musterlösung Übung 4.1 - Nicht-lineare Regression\n\nAus der Excel-Tabelle wurde das relevante Arbeitsblatt als csv gespeichert\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"readr\")\n\ncuronian <- read_delim(\"datasets/stat1-4/Curonian_spit.csv\", \",\")\nstr(curonian)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nspc_tbl_ [16 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ...1            : num [1:16] 1 2 3 4 5 6 7 8 9 10 ...\n $ Area            : num [1:16] 0.0001 0.0025 0.01 0.0625 0.25 1 4 9 16 25 ...\n $ Species.richness: num [1:16] 2.1 9.1 14.3 23.1 30.1 37.4 48.5 54.5 58 59.9 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ...1 = col_double(),\n  ..   Area = col_double(),\n  ..   Species.richness = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n```\n:::\n\n```{.r .cell-code}\nsummary(curonian)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      ...1            Area          Species.richness\n Min.   : 1.00   Min.   :  0.0001   Min.   : 2.10   \n 1st Qu.: 4.75   1st Qu.:  0.2031   1st Qu.:28.35   \n Median : 8.50   Median : 12.5000   Median :56.25   \n Mean   : 8.50   Mean   :147.1453   Mean   :50.09   \n 3rd Qu.:12.25   3rd Qu.:131.2500   3rd Qu.:69.95   \n Max.   :16.00   Max.   :900.0000   Max.   :92.40   \n```\n:::\n\n```{.r .cell-code}\n# Explorative Datenanalyse\nplot(Species.richness ~ Area, data = curonian)\n```\n\n::: {.cell-output-display}\n![](Statistik4_Loesung_1_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nEs liegt in der Tat ein nicht-linearer Zusammenhang vor, der sich gut mit nls analysieren lässt.\nDie Daten beinhalten keine erkennbaren Fehler, da der Artenreichtum der geschachtelten\nPlots mit der Fläche ansteigt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Potenzfunktion selbst definiert\nlibrary(\"nlstools\")\n# power.model <- nls(Species.richness~c*Area^z, data = curonian)\n# summary(power.model)\n```\n:::\n\nFalls die Funktion so keine Ergebnisse liefert, oder das Ergebnis unsinnig aussieht, wenn man\nes später plottet, müsste man hier geeignete Startwerte angeben, die man aus der\nBetrachtung der Daten oder aus Erfahrungen mit der Funktion für ähnliche Datensets gewinnt,etwa so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npower.model <- nls(Species.richness~c * Area^z, start = (list(c = 1, z = 0.2)), data = curonian)\nsummary(power.model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: Species.richness ~ c * Area^z\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nc 36.168960   1.408966   25.67 3.56e-13 ***\nz  0.138941   0.007472   18.60 2.88e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.142 on 14 degrees of freedom\n\nNumber of iterations to convergence: 9 \nAchieved convergence tolerance: 8.138e-06\n```\n:::\n:::\n\nDas Ergebnis ist identisch\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# logarithmische Funktion selbst definiert\nlogarithmic.model <- nls(Species.richness ~ b0 + b1 * log10(Area), data = curonian)\nsummary(logarithmic.model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: Species.richness ~ b0 + b1 * log10(Area)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nb0   43.333      1.358   31.91 1.78e-14 ***\nb1   13.281      0.654   20.31 8.75e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.265 on 14 degrees of freedom\n\nNumber of iterations to convergence: 1 \nAchieved convergence tolerance: 3.56e-09\n```\n:::\n:::\n\n\nZu den verschiedenen Funktionen mit Sättigungswert (Asymptote) gehören  Michaelis-Menten, das aymptotische Modell durch den Ursprung und die logistische\nFunktion. Die meisten gibt es in R\nals selbststartende Funktionen, was meist besser funktioniert als\nwenn man sich selbst Gedanken\nüber Startwerte usw. machen muss. Man kann sie aber auch selbst definieren\n\n_Im Folgenden habe ich ein paar unterschiedliche Sättigungsfunktionen mit verschiedenen Einstellungen durchprobiert, um zu zeigen, was alles passieren kann…_\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicmen.1 <- nls(Species.richness ~ SSmicmen(Area, Vm, K), data = curonian)\nsummary(micmen.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: Species.richness ~ SSmicmen(Area, Vm, K)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nVm  72.0108     4.2708  16.861 1.07e-10 ***\nK    0.8477     0.4371   1.939   0.0729 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.96 on 14 degrees of freedom\n\nNumber of iterations to convergence: 0 \nAchieved convergence tolerance: 3.377e-06\n```\n:::\n\n```{.r .cell-code}\n# Dasselbe selbst definiert (mit default-Startwerten)\nmicmen.2 <- nls(Species.richness ~ Vm * Area / (K + Area), data = curonian)\nsummary(micmen.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: Species.richness ~ Vm * Area/(K + Area)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nVm  46.7020     9.6748   4.827 0.000268 ***\nK   -2.1532     0.5852  -3.679 0.002477 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 35.14 on 14 degrees of freedom\n\nNumber of iterations to convergence: 23 \nAchieved convergence tolerance: 9.113e-06\n```\n:::\n:::\n\n\nHier ist das Ergebnis deutlich verschieden, ein Phänomen, das einem bei nicht-linearen\nRegressionen anders als bei linearen Regressionen immer wieder begegnen kann, da der\nIterationsalgorithmus in lokalen Optima hängen bleiben kann. Oftmals dürfte die eingebaute\nSelbststartfunktion bessere Ergebnisse liefern, aber das werden wir unten sehen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Dasselbe selbst definiert (mit sinnvollen Startwerten, basierend auf dem Plot)\nmicmen.3 <- nls(Species.richness ~ Vm * Area / (K + Area), start = list(Vm = 100, K = 1), data = curonian)\nsummary(micmen.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: Species.richness ~ Vm * Area/(K + Area)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nVm  72.0111     4.2708  16.861 1.07e-10 ***\nK    0.8477     0.4371   1.939   0.0729 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.96 on 14 degrees of freedom\n\nNumber of iterations to convergence: 22 \nAchieved convergence tolerance: 7.026e-06\n```\n:::\n:::\n\n\nWenn man sinnvollere Startwerte als die default-Werte (1 für alle Parameter) eingibt, hier etwas einen mutmasslichen Asymptoten-Wert (aus der Grafik) von Vm = ca. 100, dann bekommt man das gleiche Ergebnis wie bei der Selbsstartfunktion\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Eine asymptotische Funktion durch den Ursprung (mit implementierter Selbststartfunktion)\nasym.model <- nls(Species.richness ~ SSasympOrig(Area, Asym, lrc), data = curonian)\nsummary(asym.model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: Species.richness ~ SSasympOrig(Area, Asym, lrc)\n\nParameters:\n     Estimate Std. Error t value Pr(>|t|)    \nAsym  68.5066     4.4278  15.472 3.38e-10 ***\nlrc    0.1184     0.4864   0.244    0.811    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.88 on 14 degrees of freedom\n\nNumber of iterations to convergence: 0 \nAchieved convergence tolerance: 2.808e-06\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic.model <- nls(Species.richness ~ SSlogis(Area, asym, xmid, scal), data = curonian)\nsummary(logistic.model)\n```\n:::\n\n\n<font color=\"red\">**Error in nls(y ~ 1/(1 + exp((xmid - x)/scal)), data = xy, start = list(xmid= aux[1L], : Iterationenzahl überschritt Maximum 50**</font>\n\nDas ist etwas, was einem bei nls immer wieder passieren kann. Die Iteration ist nach der eingestellten max. Iterationszahl noch nicht zu einem Ergebnis konvergiert. Um ein Ergebnis für diese Funktion zu bekommen, müsste man mit den Einstellungen von nls „herumspielen“, etwas bei den Startwerten oder den max. Um das effizient zu machen, braucht man aber etwas Erfahrung Interationszahlen (man kann z. B. manuell die Maximalzahl der Iterationen erhöhen, indem man in den Funktionsaufruf etwa maxiter =100 als zusätzliches Argument reinschreibtn). \n\n**Logistische Regression mit Startwerten**\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic.model.2 <- nls(Species.richness ~ asym / (1 + exp((xmid - Area) / scal)),\n  control = nls.control(maxiter = 100),\n  start = (list(xmid = 1, scal = 0.2, asym = 100)), data = curonian\n)\nsummary(logistic.model.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: Species.richness ~ asym/(1 + exp((xmid - Area)/scal))\n\nParameters:\n     Estimate Std. Error t value Pr(>|t|)    \nxmid    3.970      1.608   2.469   0.0282 *  \nscal    4.112      1.676   2.453   0.0290 *  \nasym   73.634      4.507  16.339 4.79e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.11 on 13 degrees of freedom\n\nNumber of iterations to convergence: 59 \nAchieved convergence tolerance: 9.685e-06\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Vergleich der Modellgüte mittels AICc\nlibrary(\"AICcmodavg\")\ncand.models <- list()\ncand.models[[1]] <- power.model\ncand.models[[2]] <- logarithmic.model\ncand.models[[3]] <- micmen.1\ncand.models[[4]] <- micmen.2\ncand.models[[5]] <- asym.model\ncand.models[[6]] <- logistic.model.2\n\nModnames <- c(\n  \"Power\", \"Logarithmic\", \"Michaelis-Menten (SS)\", \"Michaelis-Menten\",\n  \"Asymptotic through origin\", \"Logistische Regression\"\n)\naictab(cand.set = cand.models, modnames = Modnames)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nModel selection based on AICc:\n\n                          K   AICc Delta_AICc AICcWt Cum.Wt     LL\nPower                     3  96.75       0.00   0.98   0.98 -44.38\nLogarithmic               3 104.43       7.68   0.02   1.00 -48.21\nMichaelis-Menten (SS)     3 130.67      33.92   0.00   1.00 -61.34\nLogistische Regression    4 133.53      36.78   0.00   1.00 -60.95\nAsymptotic through origin 3 135.44      38.69   0.00   1.00 -63.72\nMichaelis-Menten          3 165.17      68.42   0.00   1.00 -78.58\n```\n:::\n:::\n\n\nDiese Ergebnistabelle vergleicht die Modellgüte zwischen den fünf Modellen, die wir in unsere Auswahl reingesteckt haben. Alle haben drei geschätzte Parameter (K), also zwei Funktionsparameter und die Varianz. Das beste Modell (niedrigster AICc bzw. Delta = 0) hat das Potenzmodell (power). Das zweitbeste Modell (logarithmic) hat bereits einen Delta-AICc von mehr als 4, ist daher statistisch nicht relevant. Das zeigt sich auch am Akaike weight, das für das zweite Modell nur noch 2 % ist. Die verschiedenen Modelle mit oberem Grenzwert (3-5) sind komplett ungeeignet.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelldiagnostik für das beste Modell\nplot(nlsResiduals(power.model))\n```\n\n::: {.cell-output-display}\n![](Statistik4_Loesung_1_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nLinks oben sieht man zwar ein Muster (liegt daran, dass in diesem Fall die Plots geschachtelt, und nicht unabhängig waren), aber jedenfalls keinen problematischen Fall wie einen Bogen oder einen Keil. Der QQ-Plot rechts unten ist völlig OK. Somit haben wir auch keine problematische Abweichung von der Normalverteilung der Residuen. Da es sich bei den einzelnen Punkten allerdings bereits um arithmetische Mittelwerte aus je 8 Beobachtungen handelt, hätte man sich auch einfach auf das Central Limit Theorem beziehen können, das sagt, dass Mittelwerte automatisch einer Normalverteilung folgen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ergebnisplot\nplot(Species.richness ~ Area, pch = 16, xlab = \"Fläche [m²]\", ylab = \"Artenreichtum\", data = curonian)\nxv <- seq(0, 1000, by = 0.1)\nyv <- predict(power.model, list(Area = xv))\nlines(xv, yv, lwd = 2, col = \"red\")\nyv2 <- predict(micmen.1, list(Area = xv))\nlines(xv, yv2, lwd = 2, col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](Statistik4_Loesung_1_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nDas ist der Ergebnisplot für das beste Modell. Wichtig ist, dass man die Achsen korrekt beschriftet und nicht einfach die mehr oder weniger kryptischen Spaltennamen aus R nimmt.\n\nIm Weiteren habe ich noch eine Sättigungsfunktion (Michaelis-Menten mit Selbststarter) zum Vergleich hinzugeplottet\n\nMan erkennt, dass die Sättigungsfunktion offensichtlich den tatsächlichen Kurvenverlauf sehr\nschlecht widergibt. Im mittleren Kurvenbereich sind die Schätzwerte zu hoch, für grosse\nFlächen dann aber systematisch viel zu niedrig.\nMan kann die Darstellung im doppeltlogarithmischen Raum wiederholen, um die\nKurvenanpassung im linken Bereich besser differenzieren zu können:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ergebnisplot Double-log\nplot(log10(Species.richness) ~ log10(Area), pch = 16, xlab = \"log A\", ylab = \"log (S)\", data = curonian)\n\nxv <- seq(0, 1000, by = 0.0001)\n\nyv <- predict(power.model, list(Area = xv))\nlines(log10(xv), log10(yv), lwd = 2, col = \"red\")\n\nyv2 <- predict(micmen.1, list(Area = xv))\nlines(log10(xv), log10(yv2), lwd = 2, col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](Statistik4_Loesung_1_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nAuch hier sieht man, dass die rote Kurve zwar nicht perfekt, aber doch viel besser als die blaue Kurve ist.\n",
    "supporting": [
      "Statistik4_Loesung_1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}