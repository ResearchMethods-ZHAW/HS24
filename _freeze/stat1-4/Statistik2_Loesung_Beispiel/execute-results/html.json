{
  "hash": "574527596145236b83516eeeeb4a7d01",
  "result": {
    "markdown": "---\ndate: 2023-10-31\nlesson: Stat2\nthema: Einführung in lineare Modelle\nindex: 3\nformat:\n  html:\n    code-tools:\n      source: true\nknitr:\n    opts_chunk:\n        collapse: false\n---\n\n\n# Stat2: Lösung Beispiel\n\n## Musterlösung Beispiel\n\n-   Download dieses Lösungsscript via \"\\</\\>Code\" (oben rechts)\n-   [Lösungstext als Download](Statistik_Loesung_Beispiel.pdf)\n\n### Übungsaufgabe\n\n***(hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird)***\n\n-   Laden Sie den Datensatz decay.csv. Dieser enthält die Zahl radioaktiver Zerfälle pro Zeiteinheit (amount) für Zeitpunkte (time) nach dem Start des Experimentes.\n-   **Ermitteln Sie ein statistisches Modell, dass die Zerfallshäufigkeit in Abhängigkeit von der Zeit beschreibt.**\n-   Bitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument (oder ein z.B. mit Quarto generiertes pdf- oder html-Dokument), in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\n-   Dieser Ablauf sollte insbesondere beinhalten:\n    -   Überprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabhängige(n) Variablen\n    -   Explorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten\n    -   Auswahl und Begründung eines statistischen Verfahrens (es gibt hier mehrere statistisch korrekte Möglichkeiten!)\n    -   Ermittlung eines Modells\n    -   Durchführen der Modelldiagnostik für das gewählte Modell\n    -   Generieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\n    -   Formulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\n    -   **Zu erstellen sind (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).**\n\n## Kommentierter Lösungsweg\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(decay)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      time          amount       \n Min.   : 0.0   Min.   :  8.196  \n 1st Qu.: 7.5   1st Qu.: 21.522  \n Median :15.0   Median : 35.015  \n Mean   :15.0   Mean   : 42.146  \n 3rd Qu.:22.5   3rd Qu.: 57.460  \n Max.   :30.0   Max.   :125.000  \n```\n:::\n\n```{.r .cell-code}\nstr(decay)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nspc_tbl_ [31 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ time  : num [1:31] 0 1 2 3 4 5 6 7 8 9 ...\n $ amount: num [1:31] 125 100.2 70 83.5 100 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   time = col_double(),\n  ..   amount = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n```\n:::\n:::\n\n\nMan erkennt, dass es 31 Beobachtungen für die Zeit als Integer von Zerfällen gibt, die als rationale Zahlen angegeben werden (dass die Zahl der Zerfälle nicht ganzzahlig ist, deutet darauf hin, dass sie möglicherweise nur in einem Teil des Zeitintervalls oder für einen Teil des betrachteten Raumes gemessen und dann hochgerechnet wurde.)\n\n### Explorative Datenanalyse\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(decay$time)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nboxplot(decay$amount)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(amount ~ time, data = decay)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n:::\n\n\nWährend der Boxplot für time wunderbar symmetrisch ohne Ausreisser ist, zeigt amount eine stark rechtsschiefe (linkssteile) Verteilung mit einem Ausreisser. Das deutet schon an, dass ein einfaches lineares Modell vermutlich die Modellannahmen verletzen wird. Auch der einfache Scatterplot zeigt, dass ein lineares Modell wohl nicht adäquat ist. Wir rechnen aber erst einmal weiter.\n\n### Einfaches lineares Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.1 <- lm(amount ~ time, data = decay)\nsummary(lm.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = amount ~ time, data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.065 -10.029  -2.058   5.107  40.447 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  84.5534     5.0277   16.82  < 2e-16 ***\ntime         -2.8272     0.2879   -9.82 9.94e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.34 on 29 degrees of freedom\nMultiple R-squared:  0.7688,\tAdjusted R-squared:  0.7608 \nF-statistic: 96.44 on 1 and 29 DF,  p-value: 9.939e-11\n```\n:::\n:::\n\n\nDas sieht erst einmal nach einem Supermodell aus, höchstsignifikant und mit einem hohen R² von fast 77%. ABER: wir müssen uns noch die Modelldiagnostik ansehen...\n\n### Modelldiagnostik\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nplot(lm.1)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nHier zeigen die wichtigen oberen Plots beide massive Abweichungen vom „Soll\". Der Plot oben links zeigt eine „Banane\" und beim Q-Q-Plot oben rechts weichen die Punkte rechts der Mitte alle stark nach oben von der Solllinie ab. Wir haben unser Modell also offensichtlich falsch spezifiziert. Um eine Idee zu bekommen, was falsch ist, plotten wir noch, wie das Ergebnis dieses Modells aussähe:\n\n### Ergebnisplot\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\nplot(decay$time, decay$amount)\nabline(lm.1, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nDie Punkte links liegen alle über der Regressionslinie, die in der Mitte darunter und die ganz rechts wieder systematisch darüber (darum im Diagnostikplot oben die „Banane\"). Es liegt also offensichtlich keine lineare Beziehung vor, sondern eine curvilineare.\n\nUm diese korrekt zu analysieren, gibt es im Prinzip drei Möglichkeiten, wovon am zweiten Kurstag nur eine hatten, während die zweite und dritte in Statistik 3 und 4 folgten. Im Folgenden sind alle drei nacheinander dargestellt (in der Klausur würde es aber genügen, eine davon darzustellen, wenn die Aufgabenstellung wie oben lautet).\n\n## Variante (1): log-Transformation der abängigen Variablen\n\nDass die Verteilung der abhängigen Variable nicht normal ist, haben wir ja schon bei der explorativen Datenanalyse am Anfang gesehen. Da sie stark linkssteil ist, zugleich aber keine Nullwerte enthält, bietet sich eine Logarithmustransformation an, hier z. B. mit dem natürlichen Logarithmus.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 2))\nboxplot(decay$amount)\nboxplot(log(decay$amount))\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(decay$amount)\nhist(log(decay$amount))\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n*Die log-transformierte Variante rechts sieht sowohl im Boxplot als auch im Histogramm viel symmetrischer/besser normalverteilt aus. Damit ergibt sich dann folgendes lineares Modell*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.2 <- lm(log(amount) ~ time, data = decay)\nsummary(lm.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log(amount) ~ time, data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5935 -0.2043  0.0067  0.2198  0.6297 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.547386   0.100295   45.34  < 2e-16 ***\ntime        -0.068528   0.005743  -11.93 1.04e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.286 on 29 degrees of freedom\nMultiple R-squared:  0.8308,\tAdjusted R-squared:  0.825 \nF-statistic: 142.4 on 1 and 29 DF,  p-value: 1.038e-12\n```\n:::\n:::\n\n\nJetzt ist der R²-Wert noch höher und der p-Wert noch niedriger als im ursprünglichen linearen Modell ohne Transformation. Das erlaubt aber keine Aussage, da wir Äpfel mit Birnen vergleichen, da die abhängige Variable einmal untransformiert und einmal log-transformiert ist. Entscheidend ist die Modelldiagnostik.\n\n### Modelldiagnostik\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nplot(lm.2)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nDer Q-Q-Plot sieht jetzt exzellent aus, der Plot rechts oben hat kaum noch eine Banane, nur noch einen leichten Keil. Insgesamt deutlich besser und auf jeden Fall ein statistisch korrektes Modell.\n\nLösungen 2 und 3 greifen auf Methoden von Statistik 3 und 4 zurück, sie sind hier nur zum Vergleich angeführt\n\n## Variante (2): Quadratische Regression\n\n(kommt erst in Statistik 3) ***könnte für die Datenverteilung passen, entspricht aber nicht der physikalischen***\n\n### Gesetzmässigkeit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.quad <- lm(amount ~ time + I(time^2), data = decay)\nsummary(model.quad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = amount ~ time + I(time^2), data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.302  -6.044  -1.603   4.224  20.581 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 106.38880    4.65627  22.849  < 2e-16 ***\ntime         -7.34485    0.71844 -10.223 5.90e-11 ***\nI(time^2)     0.15059    0.02314   6.507 4.73e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.205 on 28 degrees of freedom\nMultiple R-squared:  0.908,\tAdjusted R-squared:  0.9014 \nF-statistic: 138.1 on 2 and 28 DF,  p-value: 3.122e-15\n```\n:::\n:::\n\n\nHier können wir R² mit dem ursprünglichen Modell vergleichen (beide haben amount als abhängige Grösse) und es sieht viel besser aus. Sowohl der lineare als auch der quadratische Term sind hochsignifikant. Sicherheitshalber vergleichen wir die beiden Modelle aber noch mittels ANOVA.\n\n### Vergleich mit dem einfachen Modell mittels ANOVA (es ginge auch AICc)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(lm.1, model.quad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: amount ~ time\nModel 2: amount ~ time + I(time^2)\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1     29 5960.6                                  \n2     28 2372.6  1    3588.1 42.344 4.727e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nIn der Tat ist das komplexere Modell (jenes mit dem quadratischen Term) höchstsignifikant besser. Jetzt brauchen wir noch die Modelldiagnostik.\n\n### Modelldiagnostik\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nplot(model.quad)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Variante (3): Nicht lineare Regression\n\n(die beste, hatten wir aber am 2. Tag noch nicht; mit Startwerten muss man ggf. ausprobieren) ***mit Startwerten muss man ggf. ausprobieren***\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.nls <- nls(amount ~ a * exp(-b * time), start = (list(a = 100, b = 1)), data = decay)\nsummary(model.nls)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFormula: amount ~ a * exp(-b * time)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \na 1.081e+02  4.993e+00   21.66  < 2e-16 ***\nb 8.019e-02  5.833e-03   13.75 3.12e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.243 on 29 degrees of freedom\n\nNumber of iterations to convergence: 8 \nAchieved convergence tolerance: 7.966e-06\n```\n:::\n:::\n\n\n### Modelldiagnostik\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"nlstools\")\n\nresiduals.nls <- nlsResiduals(model.nls)\nplot(residuals.nls)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nFür nls kann man nicht den normalen Plotbefehl für die Residualdiagnostik nehmen, sondern verwendet das Äquivalent aus nlstools. Die beiden entscheidenden Plots sind jetzt links oben und rechts unten. Der QQ-Plot hat im unteren Bereich einen kleinen Schönheitsfehler, aber ansonsten ist alles OK.\n\n## Ergebnisplots\n\nDa alle drei Lösungen zumindest statistisch OK waren, sollen jetzt noch die zugehörigen Ergebnisplots erstellt werden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\nxv <- seq(0, 30, 0.1)\n```\n:::\n\n\n1.  lineares Modell mit log-transformierter Abhängiger\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(decay$time, decay$amount)\nyv1 <- exp(predict(lm.2, list(time = xv)))\nlines(xv, yv1, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n2.  quadratisches Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(decay$time, decay$amount)\nyv2 <- predict(model.quad, list(time = xv))\nlines(xv, yv2, col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n3.  nicht-lineares Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(decay$time, decay$amount)\nyv3 <- predict(model.nls, list(time = xv))\nlines(xv, yv3, col = \"green\")\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_Beispiel_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nOptisch betrachtet, geben (2) und (3) den empirischen Zusammenhang etwas besser wieder als (1), da sie im linken Bereich die hohen Werte besser treffen. Man könnte sogar meinen, bei Betrachtung der Daten, dass die Werte ab time = 28 wieder leicht ansteigen, was die quadratische Funktion wiedergibt. Wer sich aber mit Physik etwas auskennt, weiss, dass Version (2) physikalisch nicht zutrifft, da die Zerfallsrate mit der Zeit immer weiter abfällt. Aufgrund der kurzen Messreihe wäre eine quadratische Funktion trotzdem eine statistisch korrekte Interpretation. Mit längeren Messreihen würde sich jedoch schnell zeigen, dass sie nicht zutrifft.\n",
    "supporting": [
      "Statistik2_Loesung_Beispiel_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}