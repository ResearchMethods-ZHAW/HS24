{
  "hash": "d60c662290adb659c272a9e836a2cc14",
  "result": {
    "markdown": "---\ndate: 2023-11-07\nlesson: Stat4\nthema: Komplexere Regressionsmethoden\nindex: 4\nformat:\n  html:\n    code-tools:\n      source: true\nknitr:\n    opts_chunk:\n        collapse: false\n---\n\n\n# Stat4: Lösung 4.2S\n\n- Download dieses Lösungsscript via \"\\</\\>Code\" (oben rechts)\n\n## Musterlösung Übung 4.2S: Multiple logistische Regression (SozWis)\n\n- **Lese-Empfehlung** Kapitel 6 von [Manny Gimond]( https://mgimond.github.io/Stats-in-R/Logistic.html)\n- **Lese-Empfehlung** Kapitel 4 von [Gareth (2016)](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n- **Lese-Empfehlung** Vorlesungsfolien von Oscar Torres-Reyna [Princeton University](https://www.princeton.edu/~otorres/LogitR101.pdf)\n\n### Kommentierter Lösungsweg\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- read_delim(\"datasets/stat1-4/Datensatz_novanimal_Uebung_Statistik4.2.csv\", delim = \";\")\n\n# sieht euch die Verteilung zwischen Mensagänger und Selbstverpfleger an\n# sind nicht gleichmässig verteilt, bei der Vorhersage müssen wir das berücksichtigen\ntable(df$mensa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  0   1 \n282 786 \n```\n:::\n\n```{.r .cell-code}\ndf |> count(mensa) # alternativ\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  mensa     n\n  <dbl> <int>\n1     0   282\n2     1   786\n```\n:::\n\n```{.r .cell-code}\n# definiert das logistische Modell und wendet es auf den Datensatz an\n\nmod0 <- glm(mensa ~ gender + member + age_groups + meat + umwelteinstellung,\n  data = df, binomial(\"logit\")\n)\nsummary.lm(mod0) # Umwelteinstellung scheint keinen Einfluss auf die\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = mensa ~ gender + member + age_groups + meat + umwelteinstellung, \n    family = binomial(\"logit\"), data = df)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-5.6740 -0.8078  0.3712  0.5867  1.2379 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  -0.18889    0.40225  -0.470 0.638750    \ngenderMann                    0.71017    0.16018   4.434 1.02e-05 ***\nmemberStudent/in             -0.63072    0.29442  -2.142 0.032404 *  \nage_groups26- bis 34-jaehrig  1.09429    0.19574   5.591 2.88e-08 ***\nage_groups35- bis 49-jaehrig  1.75379    0.45968   3.815 0.000144 ***\nage_groups50- bis 64-jaehrig  2.43530    0.78923   3.086 0.002083 ** \nmeat                          0.19945    0.05055   3.945 8.49e-05 ***\numwelteinstellung             0.19334    0.18688   1.035 0.301107    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.009 on 1060 degrees of freedom\nMultiple R-squared:  0.004042,\tAdjusted R-squared:  -0.002536 \nF-statistic: 0.6145 on 7 and 1060 DF,  p-value: 0.7443\n```\n:::\n\n```{.r .cell-code}\n# Verpflegung zu haben, gegeben die Daten\n\n# neues Modell ohne Umwelteinstellung\nmod1 <- update(mod0, ~ . -umwelteinstellung)\nsummary.lm(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = mensa ~ gender + member + age_groups + meat, family = binomial(\"logit\"), \n    data = df)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-6.0117 -0.8060  0.3584  0.6100  1.2407 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                   0.03212    0.34053   0.094 0.924860    \ngenderMann                    0.69697    0.15951   4.369 1.37e-05 ***\nmemberStudent/in             -0.64418    0.29426  -2.189 0.028806 *  \nage_groups26- bis 34-jaehrig  1.11651    0.19458   5.738 1.25e-08 ***\nage_groups35- bis 49-jaehrig  1.77409    0.45947   3.861 0.000120 ***\nage_groups50- bis 64-jaehrig  2.44683    0.78953   3.099 0.001992 ** \nmeat                          0.18070    0.04709   3.837 0.000132 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.01 on 1061 degrees of freedom\nMultiple R-squared:  0.003998,\tAdjusted R-squared:  -0.001635 \nF-statistic: 0.7098 on 6 and 1061 DF,  p-value: 0.6418\n```\n:::\n\n```{.r .cell-code}\n# Modeldiagnostik (wenn nicht signifikant, dann OK)\n1 - pchisq(mod1$deviance, mod1$df.resid) # Ok\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4509591\n```\n:::\n\n```{.r .cell-code}\n# Modellgüte (pseudo-R²)\n1 - (mod1$dev / mod1$null) # eher kleines pseudo-R2, deckt sich mit dem R-Squared aus dem obigen output summary.lm()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1354244\n```\n:::\n\n```{.r .cell-code}\n# Konfusionsmatrix vom  Datensatz\n# Model Vorhersage\n# hier ein anderes Beispiel:\npredicted <- predict(mod1, df, type = \"response\")\n\n# erzeugt eine Tabelle mit den beobachteten\n# Mensagänger/Selbstverpfleger und den Vorhersagen des Modells\nkm <- table(predicted > 0.5, df$mensa)\n# alles was höher/grosser ist als 50% ist\n# kommt in die Kategorie Mensagänger\n\n# anpassung der namen\ndimnames(km) <- list(\n  c(\"Modell Selbstverpfleger\", \"Modell Mensagänger\"),\n  c(\"Daten Selbstverpfleger\", \"Daten Mensagänger\")\n)\nkm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        Daten Selbstverpfleger Daten Mensagänger\nModell Selbstverpfleger                     87                59\nModell Mensagänger                         195               727\n```\n:::\n\n```{.r .cell-code}\n#############\n### reminder: https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62\n#############\n\n# TP = true positive: you predicted positive and it’s true; hier Vorhersage\n# Mensagänger stimmt also (727)\n\n# TN = true negative: you predicted negative and it’s true, hier Vorhersage der\n# Selbstverpfleger stimmt (87)\n\n# FP = false positive (fehler 1. art, auch Spezifizität genannt) you predicted\n# and it’s false. hier Modell sagt Mensagänger vorher\n# (obwohl in Realität Selbstverpfleger) (195)\n\n# FN = false negative (fehler 2. art, auch Sensitivität genannt),\n# you predicted negative and it’s false. hier Modell sagt Selbtverpfleger vorher\n# (obwohl in Realität Mensagänger) (59)\n\n\n# es scheint, dass das Modell häufig einen alpha Fehler macht, d.h.\n# das Modell weist keine hohe Spezifizität auf: konkret werden viele Mensagänger als\n# Selbstverpfleger vorhergesagt resp. klassifiziert. Dafür gibt es mehere Gründe:\n\n# 1) die Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger\n# Selbstverpfleger als Mensgänger im Datensatz\n\n# 2) nicht adäquates Modell z.B. link mit probit zeigt besserer fit\n\n# 3) Overfitting: wurde hier nicht berücksichtigt, in einem Paper/Arbeit\n# müsste noch einen Validierungstest gemacht werden z.B. test-train\n# Cross-Validation oder k fold Cross-Validation\n\n# kalkuliert die Missklassifizierungsrate\nmf <- 1 - sum(diag(km) / sum(km)) # ist mit knapp 23 %  eher hoch\nmf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2378277\n```\n:::\n\n```{.r .cell-code}\n# kleiner exkurs: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/\n# col wise proportion, da diese die \"Realität\" darstellt\nkm_prop <- prop.table(km, 2)\n\n# specificity = a / (a+c) => ability of a test to correctly\nspec = km_prop[1] / (km_prop[1] + km_prop[2])\nspec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3085106\n```\n:::\n\n```{.r .cell-code}\n# sensitivity = d / (b+d) => Sensitivity is the ability of a\nsens = km_prop[4] / (km_prop[3] + km_prop[4])\nsens\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9249364\n```\n:::\n:::\n\n\n### Methode\n\nIn dieser Aufgabe möchten wir untersuchen, ob wir vorhersagen können, ob jemand die Mensa besuchen wird. Wir interessieren uns dabei besonders für sozioökonomische Faktoren, die wahrgenommene Fleischkonsum und die Einstellung zur Umwelt. Die Zielgröße \"Mensa-Besuch\" ist entweder ja oder nein, daher führen wir eine \"multiple logistische Regression\" durch. Wir verwenden die Merkmale \"Alter\", \"Geschlecht\", \"Hochschulzugehörigkeit\", \"Fleischkonsum\" und \"Umwelteinstellung\" als Vorhersagevariablen. \n\nWenn du mehr über logistische Regressionen erfahren möchtest, findest du ausführlichere Informationen in den Büchern von Crawley (2015) und Gareth (2016).\n\n### Ergebnisse\n\n::: {.cell}\n::: {.cell-output-display}\n|                        | Daten Selbstverpfleger| Daten Mensagänger|\n|:-----------------------|----------------------:|-----------------:|\n|Modell Selbstverpfleger |                     87|                59|\n|Modell Mensagänger      |                    195|               727|\n\n\n\nKonfusionsmatrix\n:::\n:::\n\n\nDie Ergebnisse des logistischen Modells mit der \"logit\" Linkfunktion deuten darauf hin, dass das Modell nicht gut zu unseren Daten passt. Das bedeutet, dass es schwierig ist, basierend auf diesem Modell vorherzusagen, ob jemand in Zukunft in der Mensa essen wird oder sein Mittagessen mitbringt. Diese Schlussfolgerung wird durch den kleinen pseudo-R2-Wert (14%) und die hohe Rate der Fehlklassifikation (24%) gestützt. Wenn wir genauer hinsehen, stellen wir fest, dass das Modell häufig einen Fehler vom Typ \"Alpha\" (1. Fehler) macht, das bedeutet, es sagt oft voraus, dass jemand in die Mensa geht, obwohl sie tatsächlich ihr Essen selbst mitbringen.\n\nEs gibt mehrere Gründe für die schlechte Passung des Modells:\n\nDie Kriteriumsvariable ist in den Daten ungleich verteilt, es gibt also weniger Personen, die ihr Essen selbst mitbringen (26%) im Vergleich zu denen, die in der Mensa essen (74%).\n\nDie Prädiktorvariablen sind alle entweder kategorisch oder ordinal, was dazu führen kann, dass das Modell keine guten Ergebnisse liefert.\n\nZusammengefasst, es wäre ratsam, nach einem besseren geeigneten Modell zu suchen, insbesondere einem Modell, das mit ordinalen Prädiktorvariablen besser umgehen kann. Beispiele wären:\n\n- eine andere Link-Funktion für das GLM verwenden z.B. probit \n- [polynomiale Kontraste](https://stats.stackexchange.com/questions/195246/how-to-handle-ordinal-categorical-variable-as-independent-variable)\n- Smooth Splines [hier](https://www.frontiersin.org/articles/10.3389/fams.2017.00015/full)\n- multinomiale Regression z.M. nnet::mulitom() [hier](https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/) \n",
    "supporting": [
      "Statistik4_Loesung_2s_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}