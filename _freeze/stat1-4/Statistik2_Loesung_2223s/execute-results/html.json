{
  "hash": "93eabf945a6a6621ae0c60a7cff41120",
  "result": {
    "markdown": "---\ndate: 2023-10-31\nlesson: Stat2\nthema: Einführung in lineare Modelle\nindex: 5\nformat:\n  html:\n    code-tools:\n      source: true\nknitr:\n    opts_chunk:\n        collapse: false\n---\n\n\n# Stat2: Lösung 2.2 & 2.3S \n\n- Download dieses Lösungsscript via \"\\</\\>Code\" (oben rechts)\n\n## Musterlösung Übung 2.2\n\n### Kommentierter Lösungsweg\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#lade die Daten\ndf <- readr::read_delim(\"datasets/stat1-4/Datensatz_novanimal_Uebung_Statistik2.1.csv\", delim = \";\")\n\n# überprüft die Voraussetzungen für eine ANOVA\n# Schaut euch die Verteilungen der Mittelwerte an (plus Standardabweichungen)\n# Sind Mittelwerte nahe bei Null? \n# Gäbe uns einen weiteren Hinweis auf eine spezielle Binomial-Verteilung \ndf |>\n  group_by(label_content) |>\n  summarise(\n    tot_sold_mean = mean(tot_sold),\n    tot_sold_sd = sd(tot_sold)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  label_content tot_sold_mean tot_sold_sd\n  <chr>                 <dbl>       <dbl>\n1 Fleisch               1136.       200. \n2 Hot and Cold           308.        23.5\n3 Vegetarisch            739.       214. \n```\n:::\n\n```{.r .cell-code}\n# Boxplot\nggplot(df, aes(x = label_content, y= tot_sold)) +\n  # Achtung: Reihenfolge spielt hier eine Rolle!\n  stat_boxplot(geom = \"errorbar\", width = 0.25) +\n  geom_boxplot(fill=\"white\", color = \"black\", size = 1, width = .5) +\n  labs(x = \"\\nMenu-Inhalt\", y = \"Anzahl verkaufte Gerichte pro Woche\\n\") +\n  # achtung erster Hinweis einer Varianzheterogenität, wegen den Hot&Cold-Gerichten\n  mytheme\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_2223s_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#alternative mit base\nboxplot(df$tot_sold~df$label_content)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_2223s_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# definiert das Modell (vgl. Skript Statistik 2)\nmodel <- aov(tot_sold ~ label_content, data = df)\n\nsummary.lm(model)  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\naov(formula = tot_sold ~ label_content, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-290.250 -135.083    1.667  125.500  282.417 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                1135.58      48.92  23.211  < 2e-16 ***\nlabel_contentHot and Cold  -827.25      69.19 -11.956 1.54e-13 ***\nlabel_contentVegetarisch   -396.33      69.19  -5.728 2.15e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 169.5 on 33 degrees of freedom\nMultiple R-squared:  0.8125,\tAdjusted R-squared:  0.8012 \nF-statistic: 71.52 on 2 and 33 DF,  p-value: 1.007e-12\n```\n:::\n\n```{.r .cell-code}\n# überprüft die Modelvoraussetzungen\npar(mfrow = c(2,2))\nplot(model)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_2223s_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n:::\n\n<br> \n**Fazit**: Beim Überprüfen der Modellannahmen haben wir festgestellt, dass der Residualplot deutliche Abweichungen aufweist, die einem \"Trichter\" ähneln (wie im Statistik-Skript 2 erklärt). Dies bedeutet, dass die Annahme der Homoskedastizität nicht erfüllt ist. Welche Schritte könnten wir als nächstes unternehmen?\n\n- Wir sollten das \"Buffet\"-Menü aus unserer Analyse entfernen, da es in Wirklichkeit keine vollständigen Menüinformationen enthält. Beachte jedoch, dass dies zu einem Informationsverlust führt. Wir können diesen Ausschluss damit begründen, dass das \"Buffet\" nicht den gleichen strukturierten Menüinhalt aufweist wie die anderen Menüs.\n\n- Wir könnten eine Daten-Transformation in Betracht ziehen, zum Beispiel die Anwendung einer logarithmischen Transformation, um die Daten besser zu analysieren.\n\n- Eine andere Option wäre die Verwendung eines nicht-parametrischen Tests. Beachte jedoch, dass auch solche Tests bestimmte Voraussetzungen erfüllen müssen, um verlässliche Ergebnisse zu liefern.\n\n- Eine weitere Möglichkeit wäre die Anwendung eines general linear models (glm) mit einer Poisson- oder Quasipoisson-Link-Funktion, wie im Statistik-Skript 4 erklärt. Weitere Informationen dazu findest du im Skript Statistik 4. [Link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5869353/)\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# überprüft die Voraussetzungen des Welch-Tests:\n# Gibt es eine hohe Varianzheterogenität und ist die relative Verteilung der\n# Residuen gegeben? (siehe Statistik 2)\n# Ja Varianzheterogenität ist gegeben, aber die Verteilung der Residuen folgt\n# einem \"Trichter\", also keiner \"normalen/symmetrischen\" Verteilung um 0\n# Daher ziehe ich eine Transformation der AV einem nicht-parametrischen Test vor\n# für weitere Infos:\n# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n\n# achtung hier log10, bei einer Rücktransformation zwingend beachten\nmodel_log <- aov(log10(tot_sold) ~ label_content, data = df)\npar(mfrow = c(2, 2))\nplot(model_log) # scheint ok zu sein\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_2223s_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary.lm(model_log) # Referenzkategorie ist Fleisch\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\naov(formula = log10(tot_sold) ~ label_content, data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.198920 -0.059343  0.003477  0.062579  0.150567 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                3.04908    0.02585 117.942  < 2e-16 ***\nlabel_contentHot and Cold -0.56121    0.03656 -15.350  < 2e-16 ***\nlabel_contentVegetarisch  -0.19792    0.03656  -5.413 5.45e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.08956 on 33 degrees of freedom\nMultiple R-squared:  0.8802,\tAdjusted R-squared:  0.8729 \nF-statistic: 121.2 on 2 and 33 DF,  p-value: 6.238e-16\n```\n:::\n\n```{.r .cell-code}\nTukeyHSD(model_log) # (vgl. Statistik 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = log10(tot_sold) ~ label_content, data = df)\n\n$label_content\n                               diff        lwr        upr   p adj\nHot and Cold-Fleisch     -0.5612085 -0.6509215 -0.4714955 0.0e+00\nVegetarisch-Fleisch      -0.1979175 -0.2876305 -0.1082044 1.6e-05\nVegetarisch-Hot and Cold  0.3632910  0.2735780  0.4530041 0.0e+00\n```\n:::\n\n```{.r .cell-code}\n# Achtung Beta-Werte resp. Koeffinzienten sind nicht direkt interpretierbar\n# sie müssten zuerst wieder zurück transformiert werden, hier ein Beispiel dafür:\n# für Fleisch\n10^model_log$coefficients[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   1119.655 \n```\n:::\n\n```{.r .cell-code}\n# für Hot & Cold,\n10^(model_log$coefficients[1] + model_log$coefficients[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   307.5216 \n```\n:::\n\n```{.r .cell-code}\n# ist equivalent zu\n10^(model_log$coefficients[1]) * 10^(model_log$coefficients[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   307.5216 \n```\n:::\n\n```{.r .cell-code}\n# für Vegi\n10^(model_log$coefficients[1] + model_log$coefficients[3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   709.8501 \n```\n:::\n:::\n\n\n#### Methoden\n\nUnser Ziel war es, die Unterschiede in den wöchentlichen Verkaufszahlen für verschiedene Menüinhalte zu untersuchen. Da die Anzahl der verkauften Menüs eine Zahlenangabe ist und die Menüinhalte kategorisch sind, haben wir eine einfaktorielle ANOVA durchgeführt.\n\nAls wir das Modell überprüften, stellten wir fest, dass die Homoskedastizität stark verletzt war. Dies wurde auch durch den Boxplot bestätigt, den wir verwendet haben.\n\nUm dieses Problem anzugehen, haben wir die Verkaufszahlen durchgeführt, um sie besser vergleichbar zu machen. Anschliessend haben wir erneut eine ANOVA durchgeführt und die Modellvoraussetzungen überprüft. Diesmal stellten wir fest, dass die Homoskedastizität (gleichmässige Streuung der Residuen) und die Normalverteilung der Residuen erfüllt waren.\n\nFür weitere Informationen zur log-Transformation und zur Darstellung der Ergebnisse findest du [hier](https://dzchilds.github.io/stats-for-bio/data-transformations.html#presenting-results-from-analyses-of-transformed-data) zusätzliche Details.\n\n#### Ergebnisse\n\nDie wöchentlichen Verkaufszahlen für die verschiedenen Menüarten (Fleisch, Vegetarisch und Buffet) sind signifikant unterschiedlich (p < 0.001). Dies wird in Abbildung 1 anschaulich dargestellt, wo die Verkaufszahlen pro Menüart zu sehen sind.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Die wöchentlichen Verkaufzahlen unterscheiden sich je nach Menüinhalt stark. Das Modell wurde mit den log-tranformierten Daten gerechnet.](Statistik2_Loesung_2223s_files/figure-html/fig-plots-sol2-final-1.png){#fig-plots-sol2-final width=672}\n:::\n:::\n\n\n## Musterlösung Übung 2.3S (SozWis)\n\n- **Lese-Empfehlung** Kapitel 7 von [Manny Gimond](https://mgimond.github.io/Stats-in-R/ANOVA.html)\n\n### Kommentierter Lösungsweg\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  article_description tot_sold_mean tot_sold_sd\n  <chr>                       <dbl>       <dbl>\n1 Fav_World                    623.       179. \n2 Kitchen                      128.        22.2\n```\n:::\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_2223s_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# definiert das Modell (Skript Statistik 2)\nmodel <- aov(tot_sold ~ article_description * member, data = df)\n\nsummary.lm(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\naov(formula = tot_sold ~ article_description * member, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-91.00 -17.33   0.50  14.83  83.00 \n\nCoefficients:\n                                             Estimate Std. Error t value\n(Intercept)                                   452.333      9.734   46.47\narticle_descriptionKitchen                   -327.000     13.766  -23.75\nmemberStudierende                             340.667     13.766   24.75\narticle_descriptionKitchen:memberStudierende -334.333     19.469  -17.17\n                                             Pr(>|t|)    \n(Intercept)                                    <2e-16 ***\narticle_descriptionKitchen                     <2e-16 ***\nmemberStudierende                              <2e-16 ***\narticle_descriptionKitchen:memberStudierende   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 33.72 on 44 degrees of freedom\nMultiple R-squared:  0.9864,\tAdjusted R-squared:  0.9855 \nF-statistic:  1063 on 3 and 44 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# überprüft die Modelvoraussetzungen (Statistik 2)\npar(mfrow = c(2, 2)) # alternativ gäbe es die ggfortify::autoplot(model) funktion\nplot(model)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_2223s_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n**Fazit**: Die Überprüfung des Modells zeigt, dass die Residuen (Fehler) zwar nicht perfekt normal verteilt sind, aber die Abweichungen sind nicht allzu gross (das zeigt der Q-Q Plot). Da die Anwendung einer Log-Transformation auf die Verkaufszahlen nicht zu einer signifikanten Verbesserung führt, habe ich mich entschieden, eine ANOVA ohne die log-transformierten Verkaufszahlen durchzuführen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sieht aus, als ob die Voraussetzungen für eine Anova nur geringfügig verletzt sind\n# mögliche alternativen:\n# 0. keine Tranformation der AV (machen wir hier)\n# 1. log-transformation um die grossen werte zu minimieren (nur möglich, wenn\n# keine 0 enthalten sind und die Mittelwerte weit von 0 entfernt sind (bei uns wäre dies klar erfüllt)\n# => bei Zähldaten ist dies leider nicht immer gegeben)\n# 2. nicht parametrische Test z.B. Welch-Test, wenn hohe Varianzheterogenität\n# zwischen den Residuen\n\n# 0) keine Tranformation\n# post-hov Vergleiche\nTukeyHSD(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = tot_sold ~ article_description * member, data = df)\n\n$article_description\n                       diff      lwr       upr p adj\nKitchen-Fav_World -494.1667 -513.785 -474.5484     0\n\n$member\n                           diff      lwr      upr p adj\nStudierende-Mitarbeitende 173.5 153.8817 193.1183     0\n\n$`article_description:member`\n                                                     diff        lwr        upr\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -327.000000 -363.75650 -290.24350\nFav_World:Studierende-Fav_World:Mitarbeitende  340.666667  303.91017  377.42317\nKitchen:Studierende-Fav_World:Mitarbeitende   -320.666667 -357.42317 -283.91017\nFav_World:Studierende-Kitchen:Mitarbeitende    667.666667  630.91017  704.42317\nKitchen:Studierende-Kitchen:Mitarbeitende        6.333333  -30.42317   43.08983\nKitchen:Studierende-Fav_World:Studierende     -661.333333 -698.08983 -624.57683\n                                                  p adj\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende 0.0000000\nFav_World:Studierende-Fav_World:Mitarbeitende 0.0000000\nKitchen:Studierende-Fav_World:Mitarbeitende   0.0000000\nFav_World:Studierende-Kitchen:Mitarbeitende   0.0000000\nKitchen:Studierende-Kitchen:Mitarbeitende     0.9672944\nKitchen:Studierende-Fav_World:Studierende     0.0000000\n```\n:::\n\n```{.r .cell-code}\n# 1) Alterativ: log-transformation\nmodel_log <- aov(log10(tot_sold) ~ article_description * member, data = df)\n\nsummary.lm(model_log) # interaktion ist nun nicht mehr signifikant: vgl.\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\naov(formula = log10(tot_sold) ~ article_description * member, \n    data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.191372 -0.025043  0.003191  0.037604  0.182842 \n\nCoefficients:\n                                             Estimate Std. Error t value\n(Intercept)                                   2.65417    0.01696 156.533\narticle_descriptionKitchen                   -0.56517    0.02398 -23.569\nmemberStudierende                             0.24438    0.02398  10.191\narticle_descriptionKitchen:memberStudierende -0.21726    0.03391  -6.407\n                                             Pr(>|t|)    \n(Intercept)                                   < 2e-16 ***\narticle_descriptionKitchen                    < 2e-16 ***\nmemberStudierende                            3.71e-13 ***\narticle_descriptionKitchen:memberStudierende 8.51e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05874 on 44 degrees of freedom\nMultiple R-squared:  0.9745,\tAdjusted R-squared:  0.9728 \nF-statistic: 561.4 on 3 and 44 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# nochmals euren Boxplot zu beginn, machen diese Koeffizienten sinn?\n\n# überprüft die Modelvoraussetzungen (vgl. Skript Statistik 2)\n# bringt aber keine wesentliche Verbesserung, daher bleibe ich bei den\n# untransformierten Daten\npar(mfrow = c(2, 2))\nplot(model_log)\n```\n\n::: {.cell-output-display}\n![](Statistik2_Loesung_2223s_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# post-hov Vergleiche\nTukeyHSD(model_log) # gibt sehr ähnliche Resultate im Vergleich zum nicht-transformierten Model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = log10(tot_sold) ~ article_description * member, data = df)\n\n$article_description\n                        diff        lwr        upr p adj\nKitchen-Fav_World -0.6738029 -0.7079755 -0.6396302     0\n\n$member\n                               diff       lwr       upr p adj\nStudierende-Mitarbeitende 0.1357518 0.1015791 0.1699244     0\n\n$`article_description:member`\n                                                     diff         lwr\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -0.56517128 -0.62919652\nFav_World:Studierende-Fav_World:Mitarbeitende  0.24438333  0.18035809\nKitchen:Studierende-Fav_World:Mitarbeitende   -0.53805110 -0.60207634\nFav_World:Studierende-Kitchen:Mitarbeitende    0.80955461  0.74552937\nKitchen:Studierende-Kitchen:Mitarbeitende      0.02712017 -0.03690507\nKitchen:Studierende-Fav_World:Studierende     -0.78243444 -0.84645968\n                                                      upr     p adj\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -0.50114604 0.0000000\nFav_World:Studierende-Fav_World:Mitarbeitende  0.30840857 0.0000000\nKitchen:Studierende-Fav_World:Mitarbeitende   -0.47402586 0.0000000\nFav_World:Studierende-Kitchen:Mitarbeitende    0.87357985 0.0000000\nKitchen:Studierende-Kitchen:Mitarbeitende      0.09114541 0.6726112\nKitchen:Studierende-Fav_World:Studierende     -0.71840920 0.0000000\n```\n:::\n:::\n\n\n#### Methode\n\nUnser Ziel war es, herauszufinden, ob es Unterschiede zwischen den preisgünstigeren und teureren Menülinien in Bezug auf die Zugehörigkeit zur Hochschule gibt. Dafür haben wir eine ANOVA mit Interaktion durchgeführt, da wir eine Art von Zahlenangabe für unsere Ergebnisse und zwei Faktoren (Menülinie und Hochschulzugehörigkeit) hatten.\n\nIm ersten Modell haben wir festgestellt, dass die Voraussetzungen für eine ANOVA grösstenteils erfüllt waren, abgesehen von der Normalverteilung der Abweichungen (Residuen). Aus diesem Grund haben wir uns entschieden, auf eine log-Transformation der Zahlenangabe zu verzichten. Anschliessend haben wir zusätzlich Einzelvergleiche nach Tukey durchgeführt, um spezifische Unterschiede zwischen den Gruppen zu ermitteln.\n\nEin wichtiger Punkt zu beachten: Die Verkaufsdaten sind in Wirklichkeit Zähldaten und haben eine binomiale Verteilung, da sie keine negativen Werte haben können. Bei der Analyse stelle ich mir immer zwei Fragen:\n\n1. Wie weit ist der Mittelwert von \"Null\" entfernt? Wenn die Daten keine starken Abweichungen von der Normalverteilung aufweisen, können wir trotzdem annehmen, dass sie normal verteilt sind.\n\n2. Enthalten die Daten viele \"Nullen\"? Wenn dies der Fall ist, müssen wir eine spezielle binomiale Verteilung berücksichtigen, wie beispielsweise die Verwendung einer negativen binomialen Transformation mit einem general linear model (GLM) (siehe Skript Kapitel 4).\n\n#### Ergebnisse\n\nDie wöchentlichen Verkaufszahlen der verschiedenen Menülinien sind abhängig von der Zugehörigkeit zur Hochschule und zeigen signifikante Unterschiede (p < 0.001). Das bedeutet, dass Studierende die preisgünstigere Menülinie \"Favorite & World\" signifikant häufiger kaufen als Mitarbeitende. Überraschenderweise gibt es jedoch keine signifikanten Unterschiede zwischen Studierenden und Mitarbeitenden beim Kauf der teureren Menülinie \"Kitchen\". Um die möglichen Gründe dafür zu verstehen, sind weitere Analysen erforderlich, beispielsweise unter Einbeziehung des Menüinhalts als zus$tzlicher Faktor resp. Variable.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Box-Whisker-Plots der wöchentlichen Verkaufszahlen pro Menü-Inhalte. Kleinbuchstaben bezeichnen homogene Gruppen auf *p* < .05 nach Tukeys post-hoc-Test.](Statistik2_Loesung_2223s_files/figure-html/fig-plots-sol3-final-1.png){#fig-plots-sol3-final width=672}\n:::\n:::\n",
    "supporting": [
      "Statistik2_Loesung_2223s_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}