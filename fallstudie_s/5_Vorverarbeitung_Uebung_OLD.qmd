# KW 42+43: Übung Datenvorverarbeitung


```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#| include: false
# Benoetigte Bibliotheken ####
library(dplyr) # Data wrangling und piping
library(lubridate) # Arbeiten mit Datumsformaten
library(ggpubr) # to arrange multiple plots in one graph
library(PerformanceAnalytics) # Plotte Korrelationsmatrix
library(MuMIn) # Multi-Model Inference
library(AICcmodavg) # Modellaverageing
library(fitdistrplus) # Prueft die Verteilung in Daten
library(lme4) # Multivariate Modelle
library(blmeco) # Bayesian data analysis using linear models
library(sjPlot) # Plotten von Modellergebnissen (tab_model)
library(lattice) # einfaches plotten von Zusammenhängen zwischen Variablen
```



```{r}
# Start und Ende ####
# Untersuchungszeitraum, ich waehle hier das Jahr 2019 bis und mit Sommer 2021
depo_start <- as.Date("2017-01-01")
depo_end <- as.Date("2022-7-31")

# Start und Ende Lockdown
# definieren, wichtig fuer die spaeteren Auswertungen
lock_1_start_2020 <- as.Date("2020-03-16")
lock_1_end_2020 <- as.Date("2020-05-11")

lock_2_start_2021 <- as.Date("2020-12-22")
lock_2_end_2021 <- as.Date("2021-03-01")

# Ebenfalls muessen die erste und letzte Kalenderwoche der Untersuchungsfrist definiert werden
# Diese werden bei Wochenweisen Analysen ebenfalls ausgeklammert da sie i.d.R. unvollstaendig sind
KW_start <- isoweek(depo_start)
KW_end <- isoweek(depo_end)
```

## Aufgabe 1: Zähldaten

Die Projektstruktur steht. Nun können die Daten eingelesen und die nötigen Datentypen definiert werden. 

Lädt die Daten zuerst von Moodle herunter.

Hinweise: 

- Siehe [Einleitung] für den Standort der __Zähler 211 und 502__. 

- Die Daten sind auf Moodle unter _ReMe HS22 MSc ENR / Fallstudie Biodiversity & Ecosystems / S_Daten_ abgelegt.
1. Zähldaten zu eurem Standort (211_sihlwaldstrasse_2017_2022.csv, 502_sihluferweg_2016_2022.csv)
2. Meteodaten (order_105742_data.txt)


Die Zähldaten des Wildnispark Zürich wurden vorgängig bereinigt (z.B. wurden Stundenwerte entfernt, an denen am Zähler Wartungsarbeiten stattgefunden haben). Das macht es für uns einfach, denn wir können die Daten ohne vorgängige Bereinigung einlesen. Behaltet aber im Hinterkopf, dass die Datenaufbereitung, die Datenbereinigung mit viel Aufwand verbunden ist.

- Lest die Zählaten ein, speichert ihn unter der Variable __depo__ und sichtet den Datensatz (z.B. str(), head(), view() usw.).


```{r}
#| eval: false
depo <- read.csv("./HIER RELATIVEN DATEIPFAD EINGEBEN", sep = "HIER SEPERATOR EINGEBEN")
# Speicherort sowie Dateiname anpassen
```

__Hinweis:__ Im Stundenformat zeigen die Werte bei 11:00 die Zähldaten zwischen 11:00 bis 12:00 Uhr.

## 1a) 

- Im Datensatz des Wildnisparks sind Datum und Uhrzeit in einer Spalte. Diese müssen __getrennt__ werden (Ich schlage hier den Ansatz des piping ( |> ) vor. Damit können in einem "Rutsch" mehrere Operationen ausgeführt werden).

- Ebenfalls muss das Datum als solches definiert werden. Welches Format hat es (im Code: format = "HIER DATUMSFORMAT")?

```{r eval=FALSE}
str(depo)

depo <- depo |>
  mutate(Datum = as.character(Datum)) |>
  mutate(Datum = as.Date(Datum, format = "HIER DATUMSFORMAT")) # hier wird Text zum Datum
```

## 1b) 

Ihr könnt selbst wählen, ob ihr Fussgänger:innen oder Velos untersuchen wollt (je nachdem ob sie in eurem Datensatz vorhanden sind).

- Entfernt die überflüssigen Spalten aus dem Datensatz.Ich schlage vor, dass ihr dafuer den Befehl dplyr::select() verwendet.

## 1c) 

- Berechnen des Totals (IN + OUT), da dieses in den Daten nicht vorhanden ist (wiederum mit piping). 

Tipp: Wenn man R sagt: "addiere mir Spalte x mit Spalte y", dann macht R das für alle Zeilen in diesen zwei Spalten. Wenn man nun noch sagt: "speichere mir das Ergebnis dieser Addition in einer neuen Spalte namens __Total__", dann hat man die Aufgabe bereits gelöst. Arbeitet mit __mutate()__).

__Hinweis:__ Ihr habt das auch schon in Kapitel [Einführung und Installation] gemacht.

- Entfernt nun alle NA-Werte mit __na.omit()__.

# Aufgabe 2: Meteodaten

## 2a) 

- Lest die Meteodaten ein und speichert sie unter __meteo__.

## 2b) 

- Auch hier müssen die Datentypen manuell gesetzt werden. 

Tipp: Das Datum wird als Integer erkannt. Zuerst muss es in Text umgewandelt werden aus dem dann das eigentliche Datum herausgelesen werden kann. Das ist mühsam - darum hier der Code.

```{r eval=FALSE}
meteo <- transform(meteo, time = as.Date(as.character(time), "%Y%m%d"))
```

__Hinweis__ Was ist eigentlich Niederschlag:

https://www.meteoschweiz.admin.ch/home/wetter/wetterbegriffe/niederschlag.html

- Werden den anderen Spalten die richtigen Typen zugewiesen? Falls nicht, ändert die Datentypen.

- Nun schneiden wir den Datensatz auf die Untersuchungsdauer zu.

## 2c) 

- Jetzt müssen auch hier alle nicht verfügbare Werte (NA's) herausgefiltert werden.

Tipp: Entweder geht das mit __na.omit()__ für alle Spalten oder, etwas konservativer, können mit __filter()__ die zu filternden Spalten definiert werden. Mit folgendem Codeblock können z.B. alle Werte gefiltert werden, die in der Spalte stn nicht gleich NA sind (es werden also die Werte behalten, die vorhanden sind). Der Code muss für die anderen relevanten Spalten noch ergänzt werden.

```{r eval=FALSE}
meteo <- meteo |>
  filter(!is.na(stn))|>
  ...|>
  ...
```

__Hinweis:__ __...__ steht im Code für folgende oder vorhergehende Zeilen im Code (in einer Pipe)

- Prüft nun, wie die Struktur des data.frame (df) aussieht und ob alle NA Werte entfernt wurden (sum(is.na(df$Variable))). Stimmen alle Datentypen?


# Aufgabe 3: Datenvorverarbeitung (Mutationen)

## 3a) 

Jetzt fügen wir viele Convinience Variabeln hinzu. Wir brauchen:

1. Wochentag; der Befehl dazu ist __weekdays()__
  
Tipp: R sortiert die Levels alphabetisch. Da das in unserem Fall aber sehr unpraktisch ist, müssen die Levels manuell bestimmt werden

```{r eval=FALSE}
  ...
  mutate(Wochentag = base::factor(Wochentag,
    levels = c(
      "Montag", "Dienstag", "Mittwoch",
      "Donnerstag", "Freitag", "Samstag", "Sonntag"
    )
  ))
  ...
```

Frage: Was bedeutet __base::__ vor den eigentlichen Befehl?

- Werktag oder Wochenende?

```{r eval=FALSE}
  ...
  mutate(Wochenende = if_else(Wochentag == "Montag" | Wochentag == "Dienstag" |
    Wochentag == "Mittwoch" | Wochentag == "Donnerstag" |
    Wochentag == "Freitag", "Werktag", "Wochenende"))
  ...
```

Frage: Was bedeuten die __|__ (zu erstellen mit AltGr + 7)? Welches ist das if Argument, welches das else?

2. Kalenderwoche: __isoweek()__
3. Monat: __month()__
4. Jahr: __year()__

5. Phase Covid (Code untenstehend). Wir definieren sechs Phasen: 

  - von Anfang Untersuchungsperiode bis 1 Jahr vor Lockdown 1
  - Lockdown 1
  - zwischen den Lockdowns
  - Lockdown 2
  - Ende 2. Lockdown bis Ende Untersuchungsperiode

__Hinweis:__ 

- Ich mache den letzten Punkt nachgelagert, da zu viele Operationen in einem Schritt auch schon mal etwas durcheinander erzeugen können.

- Wir packen alle Phasen (normal, die beiden Lockdowns und Covid aber ohne Lockdown) in eine Spalte --> long-format ist schöner (und praktischer für das plotten) als wide-format.

```{r eval=FALSE}
depo <- depo |>
  mutate(Phase = if_else(Datum >= lock_1_start_2020 & Datum <= lock_1_end_2020,
    "Lockdown_1",
    if_else(Datum >= lock_2_start_2021 & Datum <= lock_2_end_2021,
      "Lockdown_2",
      if_else(Datum >= (lock_1_start_2020 - years(1)) & Datum < lock_1_start_2020,
        "Normal",
        ifelse(Datum > lock_1_end_2020 & Datum < lock_2_start_2021,
          "Inter",
          if_else(Datum > lock_2_end_2021,
            "Post", "Pre"
          )
        )
      )
    )
  ))

# hat das gepklappt?!
unique(depo$Phase)
```

Frage: Welches ist das if Argument, welches das else?

- Ändert die Datentypen der Spalten Wochenende, KW, Phase zu factor und sortiert die Levels, so dass diese Sinn machen (z.B. in Phase = Pre, Normal, Lockdown 1, Lockdown 2, Post).

## 3b)

- Nun soll noch die volle Stunde als Integer im Datensatz stehen. Diese Angabe muss etwas mühsam aus den Daten gezogen werden (darum hier der fertige Code dazu):

```{r eval = FALSE}
depo$Stunde <- as.numeric(format(as.POSIXct(depo$Zeit, format = "%H:%M:%S"), "%H"))

# ersetze 0 Uhr mit 24 Uhr (damit wir besser rechnen können)
depo$Stunde[depo$Stunde == 0] <- 24
unique(depo$Stunde)
typeof(depo$Stunde)
```

## 3c) 

Die Daten wurden durch den WPZ kalibriert (Kommastellen). 

- Rundet sie auf 0 Nachkommastellen (Ganzzahl; unser Modell kann nicht mit Kommazahlen in der ahbängigen Variable umgehen). 

- Definiert sie sicherheitshalber als Integer

- Macht das für IN, OUT und Total.

```{r eval=FALSE}
depo$... <- round(..., digits = 0)
depo$... <- as.integer(...)
```

## 3d) Tageszeit

Wir setzen den Fokus unserer Untersuchung auf die Veränderung der Besuchszahlen in der Abend- und Morgendämmerung sowie der Nacht. Dafür müssen wir diese tageszeitliche Einteilung der Daten erst machen. Da dies über den Umfang dieser Fallstudie geht, liefere ich euch hier den Code dazu.

Die wichtigsten Punkte:

- Die Tageslänge wurde für den Standort Zürich (Zeitzone CET) mit dem Package "suncalc" berechnet. Dabei wurden Sommer- und Winterzeit berücksichtigt.
- Die Einteilung der Tageszeit beruht auf dem Start und dem Ende der astronomischen Dämmerung sowie der Golden Hour. Der Morgen und der Abend wurden nach dieser Definition berechnet und um je eine Stunde Richtung Tag verlängert. 

```{r eval = FALSE}
# Einteilung Standort Zuerich
Latitude <- 47.38598
Longitude <- 8.50806

# Zur Berechnung der Tageslaege muessen wir zuerst den Start und das Ende der Sommer-
# zeit definieren
# https://www.schulferien.org/schweiz/zeit/zeitumstellung/

So_start_2017 <- as.Date("2017-03-26")
So_end_2017 <- as.Date("2017-10-29")
So_start_2018 <- as.Date("2018-03-25")
So_end_2018 <- as.Date("2018-10-28")
So_start_2019 <- as.Date("2019-03-31")
So_end_2019 <- as.Date("2019-10-27")
So_start_2020 <- as.Date("2020-03-29")
So_end_2020 <- as.Date("2020-10-25")
So_start_2021 <- as.Date("2021-03-28")
So_end_2021 <- as.Date("2021-10-31")
So_start_2022 <- as.Date("2022-03-27")
So_end_2022 <- as.Date("2022-10-30")

# Welche Zeitzone haben wir eigentlich?
# Switzerland uses Central European Time (CET) during the winter as standard time,
# which is one hour ahead of Coordinated Universal Time (UTC+01:00), and
# Central European Summer Time (CEST) during the summer as daylight saving time,
# which is two hours ahead of Coordinated Universal Time (UTC+02:00).
# https://en.wikipedia.org/wiki/Time_in_Switzerland

# Was sind Astronomische Dämmerung und Golden Hour ueberhaupt?
# https://sunrisesunset.de/sonne/schweiz/zurich-kreis-1-city/
# https://www.rdocumentation.org/packages/suncalc/versions/0.5.0/topics/getSunlightTimes

# Wir arbeiten mit folgenden Variablen:
# "nightEnd" : night ends (morning astronomical twilight starts)
# "goldenHourEnd" : morning golden hour (soft light, best time for photography) ends
# "goldenHour" : evening golden hour starts
# "night" : night starts (dark enough for astronomical observations)

lumidata <-
  getSunlightTimes(
    date = seq.Date(depo_start, depo_end, by = 1),
    keep = c("nightEnd", "goldenHourEnd", "goldenHour", "night"),
    lat = Latitude,
    lon = Longitude,
    tz = "CET"
  )

lumidata <- lumidata |>
  mutate(Jahreszeit = ifelse(date >= So_start_2017 & date <= So_end_2017 |
    date >= So_start_2018 & date <= So_end_2018 |
    date >= So_start_2019 & date <= So_end_2019 |
    date >= So_start_2020 & date <= So_end_2020 |
    date >= So_start_2021 & date <= So_end_2021 |
    date >= So_start_2022 & date <= So_end_2022,
    "Sommerzeit", "Winterzeit"
  ))

# CH ist im Im Sommer CET + 1.
# Darum auf alle relevanten Spalten eine Stunde addieren
# hinweis: ich verzichte hier auf ifelse, da es einfacher und nachvollziehbarer scheint,
# hier mit einem filter die betreffenden Spalten zu waehlen
lumidata_So <- lumidata |>
  filter(Jahreszeit == "Sommerzeit") |>
  mutate(
    nightEnd = nightEnd + hours(1),
    goldenHourEnd = goldenHourEnd + hours(1),
    goldenHour = goldenHour + hours(1),
    night = night + hours(1)
  )

lumidata_Wi <- lumidata |>
  filter(Jahreszeit == "Winterzeit")
# verbinde sommer- und winterzeit wieder
lumidata <- rbind(lumidata_So, lumidata_Wi) |>
  arrange(date)

# change data type
lumidata$date <- as.Date(lumidata$date, format = "%Y-%m-%d")

# drop unnecessary cols
lumidata <- lumidata |> dplyr::select(-lat, -lon)

# jetzt haben wir alle noetigen Angaben zu Sonnenaufgang, Tageslaenge usw.
# diese Angaben koennen wir nun mit unseren Zaehldaten verbinden:
depo <- left_join(depo, lumidata, by = c("Datum" = "date"))

# aendere alle Zeit- und Datumsangaben so, dass sie gleich sind und miteinander verrechnet werden können.
depo <- depo |>
  mutate(datetime = paste(Datum, Zeit)) |>
  mutate(datetime = as.POSIXct(datetime, format = "%Y-%m-%d  %H:%M:%S")) |>
  mutate(nightEnd = as.POSIXct(nightEnd)) |>
  mutate(goldenHourEnd = as.POSIXct(goldenHourEnd)) |>
  mutate(goldenHourEnd = goldenHourEnd + hours(1)) |>
  mutate(goldenHour = as.POSIXct(goldenHour)) |>
  mutate(goldenHour = goldenHour - hours(1)) |>
  mutate(night = as.POSIXct(night))

# im naechsten Schritt weise ich den Stunden die Tageszeiten Morgen, Tag, Abend und Nacht zu.
# diese Zuweisung basiert auf der Einteilung gem. suncalc und eigener Definition.
depo <- depo |>
  mutate(Tageszeit = if_else(datetime >= nightEnd & datetime <= goldenHourEnd, "Morgen",
    ifelse(datetime > goldenHourEnd & datetime < goldenHour, "Tag",
      ifelse(datetime >= goldenHour & datetime <= night,
        "Abend",
        "Nacht"
      )
    )
  )) |>
  mutate(Tageszeit = factor(Tageszeit, levels = c(
    "Morgen", "Tag", "Abend", "Nacht"
  )))

# # behalte die relevanten Var
depo <- depo |> dplyr::select(-nightEnd, -goldenHourEnd, -goldenHour, -night)

# Plotte zum pruefn ob das funktioniert hat
p <- ggplot(depo, aes(y = Datum, color = Tageszeit, x = Stunde)) +
  geom_jitter() +
  scale_color_manual(values = mycolors)

plotly::ggplotly(p)
```

Bei mir hat der Zusatz der Tageszeit noch zu einigen NA-Wertren geführt. Diese lösche ich einfach:

```{r eval=FALSE}
depo <- na.omit(depo)
# hat das funktioniert?
sum(is.na(depo))
```

# Aufgabe 4: Aggregierung der Stundendaten

## 4a) 

Unsere Daten liegen im Stundenformat vor. Für einige Auswertungen müssen wir aber auf ganze Tage zurückgreifen können. 

- Die Stundendaten müssen zu ganzen Tagen aggregiert werden. Macht das wiederum einer Pipe. Bezieht folgende Gruppierungen (__group_by()__) mit ein: __Datum, Wochentag, Wochenende, KW, Monat, Jahr, Phase__. Summiert die Zählmengen separat (Total, IN, OUT) auf und speichert das Resultat unter __depo_d__.

Tipp: Wenn man die Convinience Variablen als grouping variable einspeisst, dann werden sie in das neue df übernommen und müssen nicht nochmals hinzugefügt werden

```{r eval=FALSE}
depo_d <- depo |> 
  group_by(VARIABLE1, VARIABLE2, ...) |>   # Gruppieren nach den Variablen
  summarise(Total = sum(Fuss_IN + Fuss_OUT),# Berechnen der gewünschten Werte
            Fuss_IN = sum(Fuss_IN),
            ...
```

- Erstellt nun einen Datensatz depo_daytime, in welchem ihr obrigen Schritt wiederholt aber zusätzlich noch die Gruppierung "Tageszeit" nutzt.

## 4b)

- Aggregiere die Stundenwerte nach dem Monat (Gruppierungen __Monat, Jahr__) und speichert das neue df unter depo_m.

Tipp: Braucht wiederum __group_by()__ und __summarise()__. Nun brauchen wir nur noch das Total, keine Richtungstrennung mehr.

- Fügt den neu erstellten df eine Spalte mit Jahr + Monat hinzu. Das ist etwas mühsam, darum hier der fertige Code dazu:

```{r eval = FALSE}
# vergewissere, dass sicher df
depo_m <- as.data.frame(depo_m)
# sortiere das df anhand zwei Spalten aufsteigend (damit die Reihenfolge sicher stimmt)
depo_m[
  with(depo_m, order(Jahr, Monat)),
]

# Speichere dann Jahr und Monat in einer Spalte und formatiere diese als Datum
depo_m <- depo_m |>
  mutate(Ym = paste(Jahr, Monat)) |>
  mutate(Ym = lubridate::ym(Ym))
```

- Wiederholt diesen Schritt, diesmal aber mit der Gruppierung "Tageszeit" neben "Jahr" und "Monat" und speichert das Resultat unter "depo_m_daytime".

## 4c)

Macht euch mit den Daten vertraut. Plottet sie, seht euch die df's an, versteht, was sie repräsentieren.

Z.B. sind folgende Befehle und Plots wichtig:

- str()
- summarize()
- head()

- Scatterplot, x = Datum, y = Anzahl pro Zeiteinheit
- Histrogram
- usw.

__Hinweis:__ Geht noch nicht zu weit mit euren Plots. Die Idee ist, dass man sich einen Überblick über die Daten verschafft und noch keine "analysierenden" Plots erstellt.

__--> Erklärt dem Plenum am 25.10.2021 was ihr gemacht habt, was eure Daten zeigen und präsentiert diese einfachen Plots. __

Nachdem nun alle Daten vorbereitet sind folgt im nächsten Schritt die deskriptive Analyse.